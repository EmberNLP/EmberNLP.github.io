<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta property="og:type" content="website">
<meta property="og:title" content="EmberNLP">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="EmberNLP">
<meta property="og:locale" content="en">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="EmberNLP">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/"/>





  <title>EmberNLP</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">EmberNLP</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/14/2017-09-14Language Modeling with Gated Convolutional Networks/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/14/2017-09-14Language Modeling with Gated Convolutional Networks/" itemprop="url">Language Modeling with Gated Convolutional Networks</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-14T21:31:19+10:00">
                2017-09-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>This paper introduces a new neural language model that replaces the recurrent connections typically used in recurrent networks with gated temporal convolutions. Neural language models (Bengio et al., 2003) produce a representation <span class="math inline">\(\mathbf{H} = [\mathbf{h}_0,...,\mathbf{h}_N]\)</span> of the context for each word <span class="math inline">\(w_0,...,w_N\)</span> to predict the next word <span class="math inline">\(P(w_i|\mathbf{h}_i)\)</span>. Recurrent neural networks <span class="math inline">\(f\)</span> computes <span class="math inline">\(\mathbf{H}\)</span> through a recurrent function <span class="math inline">\(\mathbf{h}_i =f(\mathbf{h}_{i−1},w_{i−1})\)</span> which is an inherently sequential process that cannot be parallelized over <span class="math inline">\(i\)</span>.</p>
<p>The proposed approach convolves the inputs with a function <span class="math inline">\(f\)</span> to obtain <span class="math inline">\(\mathbf{H} = f \ast w\)</span> and therefore has no temporal dependencies, so it is easier to parallelize over the individual words of a sentence.This process will compute each context as a function of a number of preceding words.</p>
<center>
<img src="/images/2017-09-14Language%20Modeling%20with%20Gated%20Convolutional%20Networks/ComputationGraph.png">
</center>
<p>Figure above illustrates the model architecture. Words are represented by a vector embedding stored in a lookup table <span class="math inline">\(\mathbf{D}^{|V| \times e}\)</span> where <span class="math inline">\(|V|\)</span> is the number of words in the vocabulary and <span class="math inline">\(e\)</span> is the embedding size. The input to the model is a sequence of words <span class="math inline">\(w_0,...,w_N\)</span> which are represented by word embeddings <span class="math inline">\(\mathbf{E} = [\mathbf{D}_{w_0},...,\mathbf{D}_{w_N} ]\)</span>. We compute the hidden layers <span class="math inline">\(h_0,...,h_L\)</span> as</p>
<p><span class="math display">\[h_l(\mathbf{X}) = (\mathbf{X} \ast \mathbf{W} + \mathbf{b}) \otimes \sigma(\mathbf{X} \ast \mathbf{V} + \mathbf{c})\]</span></p>
<p>Where <span class="math inline">\(m\)</span>, <span class="math inline">\(n\)</span> are respectively the number of input and output feature maps and <span class="math inline">\(k\)</span> is the patch size (kernel size), <span class="math inline">\(\mathbf{X} \in \mathbb{R}^{N \times m}\)</span> is the input of layer <span class="math inline">\(h_l\)</span> (either word embeddings or the outputs of previous layers), <span class="math inline">\(\mathbf{W} \in \mathbb{R}^{k \times m \times n}\)</span>, <span class="math inline">\(\mathbf{b} \in \mathbb{R}^n\)</span>, <span class="math inline">\(\mathbf{V} \in \mathbb{R}^{k \times m \times n}\)</span>, <span class="math inline">\(\mathbf{c} \in \mathbb{R}^n\)</span> are learned parameters, <span class="math inline">\(\sigma\)</span> is the sigmoid function and <span class="math inline">\(\otimes\)</span> is the element-wise product between matrices.</p>
<p>If the input is word embeddings, then <span class="math inline">\(m=e\)</span>. For one filter (<span class="math inline">\(k \times m\)</span>), the output will be a vector (<span class="math inline">\(n \times 1\)</span>); and for <span class="math inline">\(n\)</span> filters (<span class="math inline">\(k \times m \times n\)</span>), the output will be <span class="math inline">\(n\)</span> vectors which can be concatenated to a matrix (<span class="math inline">\(n \times m\)</span>).</p>
<p>When convolving inputs, take care that <span class="math inline">\(\mathbf{h}_i\)</span> does not contain information from future words. To address this, shift the convolutional inputs to prevent the kernels from seeing future context (Oord et al., 2016a). Specifically, zero-pad the beginning of the sequence with <span class="math inline">\(k − 1\)</span> elements, assuming the first input element is the beginning of sequence marker which we do not predict and <span class="math inline">\(k\)</span> is the width of the kernel.</p>
<p>The papre also wraps the convolution and the gated linear unit in a pre-activation residual block that adds the input of the block to the output (He et al., 2015a). The blocks have a bottleneck structure for computational efficiency and each block has up to 5 layers.</p>
<h1 id="reference">Reference</h1>
<p><a href="https://arxiv.org/pdf/1612.08083.pdf" target="_blank" rel="external">Language Modeling with Gated Convolutional Networks</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/14/2017-09-14Supervised Learning of Universal Sentence Representations from Natural Language Inference Data/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/14/2017-09-14Supervised Learning of Universal Sentence Representations from Natural Language Inference Data/" itemprop="url">Supervised Learning of Universal Sentence Representations from Natural Language Inference Data</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-14T15:52:30+10:00">
                2017-09-14
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="contents">Contents</h1>
<ul>
<li>Introduction</li>
<li>The Natural Language Inference Task</li>
<li>Encoder Models
<ul>
<li>LSTM and GRU</li>
<li>BiLSTM With Mean/Max Pooling</li>
<li>Self-attentive Network</li>
<li>Hierarchical ConvNet</li>
</ul></li>
</ul>
<h1 id="introduction">Introduction</h1>
<p>This paper studies the task of learning universal representations of sentences, i.e., a sentence encoder model that is trained on a large corpus and subsequently transferred to other tasks.</p>
<p>Unlike in computer vision, where convolutional neural networks are predominant, there are multiple ways to encode a sentence using neural networks. The experiments of this paper show that an encoder based on a bi-directional LSTM architecture with max pooling, trained the Stanford Natural Language Inference dataset, yields state-of-the-art sentence embeddings compared to all existing alternative unsupervised approaches like SkipThought or FastSent, while being much faster to train.</p>
<p>The difficulty for this task is that neural networks are very good at capturing the biases of the task on which they are trained, but can easily forget the overall information or semantics of the input data by specializing too much on these biases.</p>
<h1 id="the-natural-language-inference-task">The Natural Language Inference Task</h1>
<p>The SNLI dataset consists of 570k human-generated English sentence pairs, manually labeled with one of three categories: entailment, contradiction and neutral. It captures natural language inference, also known in previous incarnations as Recognizing Textual Entailment (RTE), and constitutes one of the largest high-quality labeled resources explicitly constructed in order to require understanding sentence semantics.</p>
<center>
<img src="/images/2017-09-14Supervised%20Learning%20of%20Universal%20Sentence%20Representations%20from%20Natural%20Language%20Inference%20Data/GenericNLITrainingScheme.png">
</center>
<h1 id="encoder-models">Encoder Models</h1>
<h3 id="lstm-and-gru">LSTM and GRU</h3>
<p>Encoders apply recurrent neural networks using either LSTM or GRU modules, as in sequence to sequence encoders. For a sequence of T words <span class="math inline">\((w_1,...,w_T)\)</span>, the network computes a set of <span class="math inline">\(T\)</span> hidden representations <span class="math inline">\(h_1,h_2,...,h_T\)</span>, with <span class="math inline">\(h_t = \overrightarrow{LSTM}(w_1,...,w_T)\)</span> (or GRU units instead). A sentence is represented by the last hidden vector, <span class="math inline">\(h_T\)</span>.</p>
<h3 id="bilstm-with-meanmax-pooling">BiLSTM With Mean/Max Pooling</h3>
<center>
<img src="/images/2017-09-14Supervised%20Learning%20of%20Universal%20Sentence%20Representations%20from%20Natural%20Language%20Inference%20Data/BiLSTMMaxPoolingNetwork.png">
</center>
<span class="math display">\[\begin{equation}\begin{split}
\overrightarrow{h_t} &amp;= \overrightarrow{LSTM}_t(w_1,...,w_T)\\\\
\overleftarrow{h_t} &amp;= \overleftarrow{LSTM}_t(w_1,...,w_T)\\\\
h_t &amp;= [\overrightarrow{h_t}, \overleftarrow{h_t}]
\end{split}\end{equation}\]</span>
<h3 id="self-attentive-network">Self-attentive Network</h3>
<center>
<img src="/images/2017-09-14Supervised%20Learning%20of%20Universal%20Sentence%20Representations%20from%20Natural%20Language%20Inference%20Data/InnerAttentionNetworkArchitecture.png">
</center>
<span class="math display">\[\begin{equation}\begin{split}
\overline{h}_i &amp;= tanh(Wh_i + b_w)\\\\
\alpha_i &amp;= \frac{e^{\overline{h}^T_i u_w}}{\Sigma_i e^{\overline{h}^T_i u_w}}\\\\
u &amp;= \Sigma_i \alpha_i h_i
\end{split}\end{equation}\]</span>
<p>Where {<span class="math inline">\(h_1,...,h_T\)</span>} are the output vectors of a BiLSTM. These are fed to an affine transformation (<span class="math inline">\(W, b_w\)</span>) whcih outputs a set of keys (<span class="math inline">\(\overline{h}_1,...,\overline{h}_T\)</span>). The {<span class="math inline">\(\alpha_i\)</span>} represent the score of similarity between the keys and a learned context query vector <span class="math inline">\(u_w\)</span>. These weights are used to produce the final representation <span class="math inline">\(u\)</span>, which is a weighted linear combination of the hidden vectors.</p>
<h3 id="hierarchical-convnet">Hierarchical ConvNet</h3>
<center>
<img src="/images/2017-09-14Supervised%20Learning%20of%20Universal%20Sentence%20Representations%20from%20Natural%20Language%20Inference%20Data/HierarchicalConvNetArchitecture.png">
</center>
<p>One of the currently best performing models on classification tasks is a convolutional architecture. It concatenates different representations of the sentences at different level of abstractions. The paper introduces a faster version consisting of 4 convolutional layers. At every layer, a representation <span class="math inline">\(u_i\)</span> is computed by a max-pooling operation over the feature maps. The final representation <span class="math inline">\(u = [u_1,u_2,u_3,u_4]\)</span> concatenates representations at different levels of the input sentence. The model thus captures hierarchical abstractions of an input sentence in a fixed-size representation.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/13/2017-09-13Show attend and tell/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/13/2017-09-13Show attend and tell/" itemprop="url">Show Attend and Tell</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-13T10:01:52+10:00">
                2017-09-13
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Let’s introduce an example to explain attention mechanism. The task we want to achieve is image captioning: we want to generate a caption for a given image.</p>
<p>A <em>classic</em> image captioning system would encode the image, using a pre-trained Convolutional Neural Network that would produce a hidden state h. Then, it would decode this hidden state by using a Recurrent Neural Network (RNN), and generate recursively each word of the caption. See image below:</p>
<center>
<img src="/images/2017-09-13Show%20attend%20and%20tell/ClassicImageCaptioning.png">
</center>
<p>The problem with this method is that, when the model is trying to generate the next word of the caption, this word is usually describing only a part of the image. Using the whole representation of the image <span class="math inline">\(h\)</span> to condition the generation of each word cannot efficiently produce different words for different parts of the image. This is exactly where an attention mechanism is helpful.</p>
<p>With an attention mechanism, the image is first divided into <span class="math inline">\(L\)</span> parts, and we compute with a Convolutional Neural Network (CNN) representations of each part <span class="math inline">\(a = \{ a_1, ..., a_L \}\)</span>. When the RNN is generating a new word, the attention mechanism is focusing on the relevant part of the image, so the decoder only uses specific parts of the image.</p>
<p>On the figure below (upper row), we can see for each word of the caption what part of the image (in white) is used to generate it.</p>
<center>
<img src="/images/2017-09-13Show%20attend%20and%20tell/AttentionCaptioning.png">
</center>
<h2 id="what-is-an-attention-model">What is an attention model</h2>
<p>An attention model is a method that takes <span class="math inline">\(n\)</span> arguments <span class="math inline">\(y_1, ..., y_n\)</span> (in the precedent examples, the <span class="math inline">\(y_i\)</span> would be the <span class="math inline">\(a_i\)</span>), and a context <span class="math inline">\(c\)</span>. It returns a vector <span class="math inline">\(z\)</span> which is supposed to be the summary of the <span class="math inline">\(y_i\)</span>, focusing on information linked to the context <span class="math inline">\(c\)</span>. More formally, it returns a weighted arithmetic mean of the <span class="math inline">\(y_i\)</span>, and the weights are chosen according the relevance of each <span class="math inline">\(y_i\)</span> given the context <span class="math inline">\(c\)</span>.</p>
<p>In the example presented before, the context is the beginning of the generated sentence, the <span class="math inline">\(y_i\)</span> are the representations of the parts of the image (<span class="math inline">\(a_i\)</span>), and the output is a representation of the filtered image, with a filter putting the focus of the interesting part for the word currently generated.</p>
<p>One interesting feature of attention model is that the weight of the arithmetic means are accessible and can be plotted. This is exactly the figures we were showing before, a pixel is whiter if the weight of this image is high.</p>
<h2 id="show-attend-and-tell">Show Attend and Tell</h2>
<p>I’ll explain the details of paper <a href="https://arxiv.org/abs/1502.03044" target="_blank" rel="external">Show Attend and Tell</a>.</p>
<p>The model takes a single raw image and generates a caption <span class="math inline">\(\mathbf{y}\)</span> encoded as a sequence of <span class="math inline">\(1-of-K\)</span> encoded words. <span class="math display">\[y = \{ \mathbf{y}_1,\mathbf{y}_2,...,\mathbf{y}_C \}, \space \mathbf{y}_i \in \mathbb{R}^K\]</span></p>
<h3 id="encoder-convolutional-features">Encoder: Convolutional Features</h3>
<p>The encoder uses a convolutional neural network to extract a set of feature vectors which refer to as annotation vectors. The extractor produces <span class="math inline">\(L\)</span> vectors, each of which is a D-dimensional representation corresponding to a part of the image. <span class="math display">\[a = \{ \mathbf{a}_1,\mathbf{a}_2,...,\mathbf{a}_L\}, \space \mathbf{a}_i \in \mathbb{R}^D\]</span> In order to obtain a correspondence between the feature vectors and portions of the 2-D image, the features are extracted from a lower convolutional layer. This allows the decoder to selectively focus on certain parts of an image by selecting a subset of all the feature vectors.</p>
<p>For a concrete example, we resize the input image to <span class="math inline">\(224 \times 224\)</span>. Feature vectors <span class="math inline">\(a\)</span> use <span class="math inline">\(14 \times 14 \times 512\)</span> dimensional feature maps of layer <span class="math inline">\(conv5\_3\)</span> of VGG net. So the number of regions is <span class="math inline">\(L = 14 \times 14 = 196\)</span>, and the dimension of each feature vector is <span class="math inline">\(D = 512\)</span>.</p>
<h3 id="decoder-lstm-network">Decoder: LSTM network</h3>
The decoder is a LSTM network that produces a caption bt generating one word at ecery time step conditioned on a context vector, the previous hidden state and the previously generated words.
<center>
<img src="/images/2017-09-13Show%20attend%20and%20tell/DecoderLSTM.png">
</center>
From the figure above, we can see:
<span class="math display">\[\begin{equation}\begin{split}
f_t &amp;= \sigma(W_f[Ey_{t-1}, h_{t-1}, z_t]) \\\\
i_t &amp;= \sigma(W_i[Ey_{t-1}, h_{t-1}, z_t]) \\\\
o_t &amp;= \sigma(W_o[Ey_{t-1}, h_{t-1}, z_t]) \\\\
g_t &amp;= tanh(W_g[Ey_{t-1}, h_{t-1}, z_t]) \\\\
c_t &amp;= f_t \odot c_{t-1} + i_t \odot g_t\\\\
h_t &amp;= o_t \odot tanh(c_t)
\end{split}\end{equation}\]</span>
<p>Here, <span class="math inline">\(i_t,f_t,c_t,o_t,h_t\)</span> are the input, forget, memory, output and hidden state of the LSTM, respectively.</p>
<ul>
<li><span class="math inline">\(y_{t-1}\)</span>: the previously generated word, <span class="math inline">\(y_i \in \mathbb{R}^K\)</span>, <span class="math inline">\(K\)</span> is the size of the vocabulary.</li>
<li><span class="math inline">\(E\)</span>: the Embedding lookup table which are learned parameters initialized randomly, <span class="math inline">\(E \in \mathbb{R}^{m \times K}\)</span>, <span class="math inline">\(m\)</span> denotes the Embedding dimensionality.</li>
<li><span class="math inline">\(z_t\)</span>: the context vector, it’s a function of annotation vectors <span class="math inline">\(a\)</span>, capturing the visual information associated with a particular input location, <span class="math inline">\(z_t \in \mathbb{R}^D\)</span></li>
</ul>
<p>It’s time to illustrate the attention part, that is where <span class="math inline">\(z_t\)</span> comes from.</p>
<p>In simple terms, the context vectors <span class="math inline">\(\mathbf{z}_t\)</span> is a dynamic representation of the relevant part of the image input at time <span class="math inline">\(t\)</span>. Mechanism <span class="math inline">\(\phi\)</span> is defined to compute <span class="math inline">\(\mathbf{z}_t\)</span> from annotatioin vectors <span class="math inline">\(\mathbf{a}_i, i=1,2,...,L\)</span> corresponding to the features extracted at different image locations. For each location <span class="math inline">\(i\)</span>, the mechanism generates a positive weight location <span class="math inline">\(\alpha_i\)</span> which can be interpreted either as the probability that location <span class="math inline">\(i\)</span> is the right place to focus for producing the next word (the ‘hard’ but stochastic attention mechanism), or as the relative importance to give to location <span class="math inline">\(i\)</span> in blending the <span class="math inline">\(a_i\)</span>’s together. The weight <span class="math inline">\(\alpha_i\)</span> of each annotation vectors <span class="math inline">\(a_i\)</span> is computed using an attention model <span class="math inline">\(f_{att}\)</span> which is a multilayer perceptron conditioned on the previous hidden state <span class="math inline">\(h_{t-1}\)</span> <span class="math display">\[e_{ti} = f_{att} ( \mathbf{a}_i, \mathbf{h}_{t-1} )\]</span> <span class="math display">\[\alpha_{ti} = \frac{exp(e_{ti})}{\Sigma^L_{k=1}exp} (e_{tk} )\]</span> Once the weigths (which sums to 1) are computed, the context vector <span class="math inline">\(\mathbf{z}_t\)</span> is computed by: <span class="math display">\[\mathbf{z}_t = \phi ( \{ \mathbf{a}_i \}, \{ \alpha_i \})\]</span> For <em><strong>soft attention</strong></em>: <span class="math display">\[\mathbf{z}_t = \phi ( \{ \mathbf{a}_i \}, \{ \alpha_i \}) = \Sigma^L_{i=1} \alpha_i \mathbf{a}_i\]</span></p>
<p>The initial memory state and hidden state of the LSTM are predicted by an average of the annotation vectors fed through two separate MLPs: <span class="math display">\[\mathbf{c}_0 = f_{init,c} (\frac{1}{L} \Sigma^L_i \mathbf{a}_1)\]</span> <span class="math display">\[\mathbf{h}_0 = f_{init,h} (\frac{1}{L} \Sigma^L_i \mathbf{a}_1)\]</span></p>
<h3 id="output-layer">Output Layer</h3>
<p>Output is a deep layer to compute the output word probability given the LSTM state, the context voector and the previous word: <span class="math display">\[p(y_t|a,y_{t-1}) \propto exp(L_0(Ey_{t-1} + L_hh_t + L_zz_t))\]</span></p>
<h1 id="reference">Reference</h1>
<ol style="list-style-type: decimal">
<li><a href="https://arxiv.org/abs/1502.03044" target="_blank" rel="external">Show, Attend and Tell: Neural Image Caption Generation with Visual Attention</a></li>
<li><a href="https://blog.heuritech.com/2016/01/20/attention-mechanism/" target="_blank" rel="external">Attention Mechanism</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/06/2017-09-06Siamese Network/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/06/2017-09-06Siamese Network/" itemprop="url">Siamese Network</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-06T16:56:51+10:00">
                2017-09-06
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>The main idea of Siamese Network is to map the inputs to a new space by a function which can be learned by neural network. Then it is able to use similarity measurement like (Euclidean Metric or Cosine Similarity) to compare the extent of similarity. During training, the goal is to minimize the value of cost functon of the pairs of samples from same category, in the meantime, maximize the value of cost function of the pairs from different categories. For a given neural network (CNN, RNN), the goal is to optimize its parameters <span class="math inline">\(\mathbf{W}\)</span> to make:</p>
<p><span class="math inline">\(E_w = \left \| G_w(X_1) - G_w(X_2) \right \|\)</span>, small if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are in the same category</p>
<p><span class="math inline">\(E_w = \left \| G_w(X_1) - G_w(X_2) \right \|\)</span>, large if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are in the different categories</p>
<p>The only assumption about W is differentiable.</p>
<p>And the cost function is defined as below: <span class="math display">\[\mathcal{L}(W) = \Sigma^n_{i=1} (1-Y)L_G(E_w(x_1,x_2)^i) + YL_I(E_w(X_1,X_2)^i)\]</span></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/05/2017-09-05PixelCNN/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/05/2017-09-05PixelCNN/" itemprop="url">PixelCNN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-05T14:49:49+10:00">
                2017-09-05
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="content">Content</h1>
<ul>
<li>PixelCNN</li>
<li>Gated Convolutional Layer</li>
<li>BlindSpot And Solution</li>
<li>Conditional PixelCNN</li>
<li>fast PixelCNN ++</li>
<li>PixelRNN</li>
</ul>
<h2 id="pixelcnn">PixelCNN</h2>
<p>PixelCNNs (and PixelRNNs) model the joint distribution of pixels over an image <span class="math inline">\(x\)</span> as the following product of conditional distributions, where <span class="math inline">\(x_i\)</span> is a single pixel: <span class="math display">\[p(x) = \prod\limits^{n^2}_{i=1}p(x_i|x_1,...,x_{i-1})\]</span> The ordering of the pixel dependencies is in raster scan order: row by row and pixel by pixel within every row. Every pixel therefore depends on all the pixels above and to the left of it, and not on any of other pixels.</p>
<p>In PixelCNN every conditional distribution is modelled by a convolutional neural network. To make sure the CNN can only use information about pixels above and to the left of the current pixel, the convolution are <em><strong>masked</strong></em> as the figure below.</p>
<center>
<img src="/images/2017-09-05PixelCNN/PixelCNN.png">
</center>
<p>For image with only one channel (like mnist dataset): <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">filter_mid_h = shape[0]//2</div><div class="line">filter_mid_w = shape[1]//2</div><div class="line">mask_filter =np.ones(shape, dtype= np.float32)</div><div class="line">mask_filter[filter_mid_h,filter_mid_w+1:, :, :] = 0.</div><div class="line">mask_filter[filter_mid_h+1:, :, :, :] = 0.</div><div class="line"><span class="comment"># W *= mask_filter</span></div></pre></td></tr></table></figure></p>
<p>For a <span class="math inline">\(7 * 7\)</span> filter, the mask tensor should look like this: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div></pre></td><td class="code"><pre><div class="line">array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.],</div><div class="line">       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],</div><div class="line">       [ 1.,  1.,  1.,  1.,  1.,  1.,  1.],</div><div class="line">       [ 1.,  1.,  1.,  0.,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.],</div><div class="line">       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.]])</div></pre></td></tr></table></figure></p>
<p>For colourful images with three channels (R,G,B), in the first layer, each of the RGB channels is connected to previous channels and to the context, but is not connected to itself. In subsequent layers, the channels are also connected to themselves (Shown below).</p>
<center>
<img src="/images/2017-09-05PixelCNN/RGB.png">
</center>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line">def bmask(i_in, i_out):</div><div class="line">	cin_idx = np.expand_dims(np.arange(Cin) % 3 == i_in, 1)</div><div class="line">    cout_idx = np.expand_dims(np.arange(Cout) % 3 == i_out, 0)</div><div class="line">    a1, a2 = np.broadcast_arrays(cin_idx, cout_idx)</div><div class="line">    <span class="built_in">return</span> a1 * a2</div><div class="line"></div><div class="line"><span class="keyword">for</span> j <span class="keyword">in</span> range(3):</div><div class="line">    mask_filter[filter_mid_h,filter_mid_w][bmask(j,j)] = 0. <span class="keyword">if</span> mask ==<span class="string">"A"</span> <span class="keyword">else</span> 1.</div><div class="line"></div><div class="line">mask_filter[filter_mid_h,filter_mid_w][bmask(1, 0)] = 0.</div><div class="line">mask_filter[filter_mid_h,filter_mid_w][bmask(2, 0)] = 0.</div><div class="line">mask_filter[filter_mid_h,filter_mid_w][bmask(2, 1)] = 0.</div></pre></td></tr></table></figure>
<p>For example, <span class="math inline">\(i_{in} = 3\)</span>, <span class="math inline">\(i_{out} = 6\)</span>, the last two dimensions should look like this: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># Mask A</span></div><div class="line">array([[ 0.,  1.,  1.,  0.,  1.,  1.],</div><div class="line">       [ 0.,  0.,  1.,  0.,  0.,  1.],</div><div class="line">       [ 0.,  0.,  0.,  0.,  0.,  0.]])</div><div class="line"><span class="comment"># Mask B</span></div><div class="line">array([[ 1.,  1.,  1.,  1.,  1.,  1.],</div><div class="line">       [ 0.,  1.,  1.,  0.,  1.,  1.],</div><div class="line">       [ 0.,  0.,  1.,  0.,  0.,  1.]])</div></pre></td></tr></table></figure></p>
<center>
<img src="/images/2017-09-05PixelCNN/PixelCNNPred.png">
</center>
<p>As shown above, the 256 possible values for each colour channel are then modelled using a softmax.</p>
<p>PixelCNN typically consists of a stack of masked convolutional layers that takes an <span class="math inline">\((N,N,3)\)</span> image as input and produces <span class="math inline">\((N,N,3,256)\)</span> predictions as output. The use of convolutions allows the predictions for all the pixels to be made in parallel during training.</p>
<p>During sampling the predictions are sequential: every time a pixel is predicted, it is fed back into the network to predict the next pixel. This sequentiality is essential to generating high quality images, as it allows every pixel to depend in a highly non-linear and multimodal way on the previous pixels.</p>
<h2 id="gated-convolutional-layer">Gated Convolutional Layer</h2>
<p>For a gated convolutional layer, relu activation block with more complex combination of sigmoid (as a forget gate) and tanh (as real activation). It suggests that: <span class="math display">\[\mathbf{y} = tanh(W_{k,f} \ast \mathbf{x}) \odot \sigma(W_{k,g} \ast \mathbf{x})\]</span></p>
<p>Here is the code to illustrate the formula: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">W_f = get_weights(W_shape, <span class="string">"v_W"</span>, mask=mask)</div><div class="line">W_g = get_weights(W_shape, <span class="string">"h_W"</span>, mask=mask)</div><div class="line"></div><div class="line">b_f = tf.get_variable(<span class="string">"v_b"</span> , b_shape, tf.float32, tf.zeros_initializer)</div><div class="line">b_g = tf.get_variable(<span class="string">"h_b"</span> , b_shape, tf.float32, tf.zeros_initializer)</div><div class="line"></div><div class="line">conv_f = tf.nn.conv2d(input_layer, W_f, strides=[1,1,1,1], padding=<span class="string">'SAME'</span>)</div><div class="line">conv_g = tf.nn.conv2d(input_layer, W_g, strides=[1,1,1,1], padding=<span class="string">'SAME'</span>)</div><div class="line">output_layer = tf.mul(tf.tanh(conv_f + b_f), tf.sigmoid(conv_g+ b_g))</div></pre></td></tr></table></figure></p>
<h2 id="blindspot-and-solution">BlindSpot And Solution</h2>
<p>Note that a significant portion of the input image is ignored by the masked convolutional architecture. This ‘blind spot’ can cover as much as a quarter of the potential receptive field (e.g., when using 3x3 filters), meaning that none of the content to the right of the current pixel would be taken into account.</p>
<center>
<img src="/images/2017-09-05PixelCNN/BlindSpot.png">
</center>
<p>To gain some intuition about blind spot, following code may help: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div></pre></td><td class="code"><pre><div class="line"><span class="comment"># create 5x5 input</span></div><div class="line"><span class="comment"># chainer requires input to have shape [BATCH, CHANNELS, HEIGHT, WIDTH]</span></div><div class="line">input = np.arange(25).reshape([1,1,5,5]).astype(<span class="string">'f'</span>)</div><div class="line"><span class="comment"># array([[[[    0.,     1.,     2.,     3.,     4.],</span></div><div class="line"><span class="comment">#          [    5.,     6.,     7.,     8.,     9.],</span></div><div class="line"><span class="comment">#          [   10.,    11.,    12.,    13.,    14.],</span></div><div class="line"><span class="comment">#          [   15.,    16.,    17.,    18.,    19.],</span></div><div class="line"><span class="comment">#          [   20.,    21.,    22.,    23.,    24.]]]], dtype=float32)</span></div><div class="line"></div><div class="line"><span class="comment"># create kernel of ones so it just sums all values within</span></div><div class="line"><span class="comment"># use one for simplicity: easy to check</span></div><div class="line">kernel = np.ones([3, 3])</div><div class="line"><span class="comment"># turn to proper type 'A' mask</span></div><div class="line">kernel[2:, :] = 0.0</div><div class="line">kernel[1, 1:] = 0.0</div><div class="line"><span class="comment"># array([[ 1.,  1.,  1.],</span></div><div class="line"><span class="comment">#        [ 1.,  0.,  0.],</span></div><div class="line"><span class="comment">#        [ 0.,  0.,  0.]])</span></div><div class="line"></div><div class="line"><span class="comment"># create two convolution layers with total receptive field size 5x5</span></div><div class="line"><span class="comment"># so out input is exact fit</span></div><div class="line">import chainer.links as L</div><div class="line"></div><div class="line">l1 = L.Convolution2D(1, 1, ksize=3, initialW=kernel)</div><div class="line">l2 = L.Convolution2D(1, 1, ksize=3, initialW=kernel)</div><div class="line"></div><div class="line"><span class="comment"># here is the trick: pixel at [1, 4] position will be inside blind spot</span></div><div class="line"><span class="comment"># if we perform convolution its value won't be included in final sum</span></div><div class="line"><span class="comment"># so let's increase its value so it would be easy to check</span></div><div class="line">input[:, :, 1, 4] = 1000</div><div class="line"><span class="comment"># array([[[[    0.,     1.,     2.,     3.,     4.],</span></div><div class="line"><span class="comment">#          [    5.,     6.,     7.,     8.,  1000.],</span></div><div class="line"><span class="comment">#          [   10.,    11.,    12.,    13.,    14.],</span></div><div class="line"><span class="comment">#          [   15.,    16.,    17.,    18.,    19.],</span></div><div class="line"><span class="comment">#          [   20.,    21.,    22.,    23.,    24.]]]], dtype=float32)</span></div><div class="line"></div><div class="line">output = l2(l1(input)).data</div><div class="line"><span class="comment"># array([[[[ 64.]]]], dtype=float32)</span></div><div class="line"><span class="comment"># Viola! Sum is lesser that 1000 which means pixel at [1, 4] wasn't seen!</span></div><div class="line"></div><div class="line"><span class="comment"># Otherwise, let's return it value back</span></div><div class="line">input[:, :, 1, 4] = 9</div><div class="line"><span class="comment"># array([[[[    0.,     1.,     2.,     3.,     4.],</span></div><div class="line"><span class="comment">#          [    5.,     6.,     7.,     8.,     9.],</span></div><div class="line"><span class="comment">#          [   10.,    11.,    12.,    13.,    14.],</span></div><div class="line"><span class="comment">#          [   15.,    16.,    17.,    18.,    19.],</span></div><div class="line"><span class="comment">#          [   20.,    21.,    22.,    23.,    24.]]]], dtype=float32)</span></div><div class="line"></div><div class="line"><span class="comment"># perform computation again..</span></div><div class="line">output = l2(l1(input)).data</div><div class="line"><span class="comment"># array([[[[ 64.]]]], dtype=float32)</span></div><div class="line"><span class="comment"># Another evidence: no matter what value we assign to it final sum doesn't change</span></div><div class="line"><span class="comment"># That proves it's within blind spot and we can't access information at it.</span></div></pre></td></tr></table></figure></p>
<p>To remove the blind spot, authors introduce neat idea: they split convolution into two different operations: two separate stacks - vertical and horizontal.</p>
<center>
<img src="/images/2017-09-05PixelCNN/PixelCNNStack.png">
</center>
<p>Here we have horizontal stack (in purple): convolution operation that conditions on only current row, so it has access to left pixels. Vertical stack (blue) has access to all top pixels. Implementation details would follow. Note that horizontal and vertical stacks are sort of independent: vertical stack should not access any information horizontal stack has: otherwise it will have access to pixels it shouldn’t see. But vertical stack can be connected to vertical as it predicts pixel following those in vertical stack.</p>
<h2 id="conditional-pixelcnn">Conditional PixelCNN</h2>
<p>Given a high-level image description represented as a latent vector <span class="math inline">\(\mathbf{h}\)</span>, we seek to model the conditional distribution <em><span class="math inline">\(p(\mathbf{x}|\mathbf{h})\)</span></em> of images suiting this description. Formally the conditional PixelCNN models the following distribution: <span class="math display">\[p(\mathbf{x}|\mathbf{h}) = \prod\limits^{n^2}_{i=1}p(x_i|x_1,x_2,...,x_{i-1},\mathbf{h})\]</span></p>
<p>To model the conditional distribution by adding terms that depend on <span class="math inline">\(\mathbf{h}\)</span> to the activations before the nonlinearities, which now becomes: <span class="math display">\[\mathbf{y} = tanh(W_{k,f} \ast \mathbf{x} + V^T_{k,f} \mathbf{h}) \odot \sigma(W_{k,g} \ast \mathbf{x} + V^T_{k,g} \mathbf{h})\]</span></p>
<p>where k is the layer number. If <span class="math inline">\(\mathbf{h}\)</span> is a one-hot encoding that specifies a class this is equivalent to adding a class dependent bias at every layer. Notice that the conditioning does not depend on the location of the pixel in the image; this is appropriate as long as <span class="math inline">\(\mathbf{h}\)</span> only contains information about what should be in the image and not where.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line">def conditional_gated_conv(self):</div><div class="line">    W_f = get_weights(self.W_shape, <span class="string">"v_W"</span>, mask=self.mask)</div><div class="line">    W_g = get_weights(self.W_shape, <span class="string">"h_W"</span>, mask=self.mask)</div><div class="line">    <span class="keyword">if</span> self.conditional is not None:</div><div class="line">        h_shape = int(self.conditional.get_shape()[1])</div><div class="line">        V_f = get_weights([h_shape, self.W_shape[3]], <span class="string">"v_V"</span>)</div><div class="line">        b_f = tf.matmul(self.conditional, V_f)</div><div class="line">        V_g = get_weights([h_shape, self.W_shape[3]], <span class="string">"h_V"</span>)</div><div class="line">        b_g = tf.matmul(self.conditional, V_g)</div><div class="line"></div><div class="line">        b_f_shape = tf.shape(b_f)</div><div class="line">        b_f = tf.reshape(b_f, (b_f_shape[0], 1, 1, b_f_shape[1]))</div><div class="line">	    b_g_shape = tf.shape(b_g)</div><div class="line">        b_g = tf.reshape(b_g, (b_g_shape[0], 1, 1, b_g_shape[1]))</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">        b_f = get_bias(self.b_shape, <span class="string">"v_b"</span>)</div><div class="line">        b_g = get_bias(self.b_shape, <span class="string">"h_b"</span>)</div><div class="line"></div><div class="line">    conv_f = conv_op(self.fan_in, W_f)</div><div class="line">    conv_g = conv_op(self.fan_in, W_g)</div><div class="line">       </div><div class="line">    self.fan_out = tf.multiply(tf.tanh(conv_f + b_f), tf.sigmoid(conv_g + b_g))</div></pre></td></tr></table></figure>
<h1 id="reference">Reference</h1>
<ol style="list-style-type: decimal">
<li><a href="https://arxiv.org/pdf/1601.06759.pdf" target="_blank" rel="external">Pixel Recurrent Neural Networks</a></li>
<li><a href="https://arxiv.org/pdf/1606.05328.pdf" target="_blank" rel="external">Conditional Image Generation with PixelCNN Decoders</a></li>
<li><a href="http://sergeiturukin.com/2017/02/24/gated-pixelcnn.html" target="_blank" rel="external">sergeiturukin’s Post</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/04/2017-09-04The Intuition Behind LSTM/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/04/2017-09-04The Intuition Behind LSTM/" itemprop="url">Intuition Behind LSTM</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-04T10:55:06+10:00">
                2017-09-04
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Intuition/" itemprop="url" rel="index">
                    <span itemprop="name">Intuition</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="content">Content</h1>
<ul>
<li>A mathematically Sufficient Condition For Vanishing Sensitivity</li>
<li>A minimum Weight Initialization to Avoid Vanishing Gradients</li>
<li>Written memories: the intuition behind LSTMs</li>
<li>Different Between Tanh and Sigmoid Function</li>
</ul>
<h2 id="a-mathematically-sufficient-condition-for-vanishing-sensitivity">A mathematically Sufficient Condition For Vanishing Sensitivity</h2>
<p>This is a mathematical proof of a sufficient condition for vanishing sensitivity in vanilla RNNs. The proof here also takes advantage of the mean value theorem to go one step further than Pascanu et al. and reach a slightly stronger result, effectively showing vanishing causation rather than vanishing sensitivity. Note that mathematical analyses of vanishing and exploding gradients date back to the early 1990s, in Bengio et al. (1994) and Hochreiter (1991) (original in German, relevant portions summarized in Hochreiter and Schmidhuber (1997)).</p>
To begin, from the definition of a vanilla RNN cell, we have: <span class="math display">\[s_{t+1} = \phi (z_t), where \space z_t = Ws_t + Ux_{t+1} + b\]</span> Recall the <em><strong>Mean value theorem</strong></em>: If a function <span class="math inline">\(f\)</span> is continuous on the closed interval <span class="math inline">\([a,b]\)</span>, and differentiable on the open interval <span class="math inline">\((a,b)\)</span> , then there exists a point <span class="math inline">\(c\)</span> in <span class="math inline">\((a,b)\)</span> such that: <span class="math display">\[f&#39;(c) = \frac{f(b)-f(a)}{b-a}\]</span> Applying the mean value theorem, we get that there exists <span class="math inline">\(c \in [z_t, z_t + \Delta z_t]\)</span> such that:
<span class="math display">\[\begin{equation}\begin{split}
\Delta S_{t+1} &amp;= [\phi&#39;(c)] \Delta z_t\\\\
&amp;= [\phi&#39;(c)] \Delta (Ws_t)\\\\
&amp;= [\phi&#39;(c)] W\Delta(s_t)
\end{split}\end{equation}\]</span>
<p>Now let <span class="math inline">\(\left \| A \right \|\)</span> represent the matrix 2-norm, <span class="math inline">\(\left | v \right |\)</span>the Euclidean vector norm, and define: <span class="math display">\[\gamma = sup_{c \in \{z_t, z_t + \Delta z_t\}} \left \| [\phi&#39; (c)] \right \|\]</span> Note that for the logistic sigmoid, <span class="math inline">\(\gamma \leq \frac{1}{4}\)</span>, and for tanh, <span class="math inline">\(\gamma \leq 1\)</span>.</p>
Taking the vector norm of each side, we obtain, where the first inequality comes from the definition of the 2-norm (applied twice), and second from the definition of supremum:
<span class="math display">\[\begin{equation}\begin{split}
\left | \Delta s_{t+1} \right | &amp;= \left | [\phi&#39;(c)] W \Delta s_t \right |\\\\
&amp;\leq \left \| [\phi&#39;(c)] \right \| \left \| W \right \| \left | \Delta s_t \right |\\\\
&amp;\leq \gamma \left \| W \right \| \left | \Delta s_t \right |\\\\
&amp;= \left \| \gamma W \right \| \left | \Delta s_t \right |
\end{split}\end{equation}\]</span>
<p>By expanding this formula over <span class="math inline">\(k\)</span> time steps we get: <span class="math display">\[\left | \Delta s_{t+k} \right | \leq \left \| \gamma W \right \|^k \left | \Delta s_t \right |\]</span> So that: <span class="math display">\[\frac{\left | \Delta s_{t+k} \right |}{\left | \Delta s_t \right |} = \left \| \gamma W \right \|^k\]</span></p>
<p>Therefore, if <span class="math inline">\(\left \| \gamma W \right \| &lt; 1\)</span> , we have that <span class="math inline">\(\frac{\left | \Delta s_{t+k} \right |}{\left | \Delta s_t \right |}\)</span> decreases exponentially in time.</p>
<h2 id="a-minimum-weight-initialization-to-avoid-vanishing-gradients">A minimum Weight Initialization to Avoid Vanishing Gradients</h2>
<p>It is beneficial to find a weight initialization that will not immediately suffer from this problem. Extending the above analysis to find the initialization of <span class="math inline">\(W\)</span> that gets us as close to equality as possible leads to a nice result. First, let us assume that <span class="math inline">\(\phi = tanh\)</span> and take <span class="math inline">\(\gamma = 1\)</span>. Our goal is to find an initialization of W for which:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\left \| \gamma W \right \| = 1\)</span></li>
<li>We get as close to equality as possible in above equation.</li>
</ol>
<p>From point 1, since we took <span class="math inline">\(\gamma\)</span> to be 1, we have <span class="math inline">\(\left \| W \right \| = 1\)</span>. From point 2, we get that we should try to set all singular values of <span class="math inline">\(W\)</span> to 1, not just the largest. Then, if all singular values of <span class="math inline">\(W\)</span> equal 1, that means that the norm of each column of <span class="math inline">\(W\)</span> is 1 (since each column is <span class="math inline">\(We_i\)</span> for some elementary basis vector <span class="math inline">\(e_i\)</span> and we have <span class="math inline">\(\left |We_i \right | = \left | e_i \right | = 1\)</span>). That means that for column <span class="math inline">\(j\)</span> we have: <span class="math display">\[\Sigma_i w_{ij}^2 = 1\]</span></p>
<p>There are <span class="math inline">\(n\)</span> entries in column <span class="math inline">\(j\)</span>, and we are choosing each from the same random distribution, so let us find a distribution for a random weight <span class="math inline">\(w\)</span> for which: <span class="math display">\[n\mathbb{E}(w^2) = 1\]</span></p>
<p>Now let’s suppose we want to initialize <span class="math inline">\(w\)</span> uniformly in the interval <span class="math inline">\([-R,R]\)</span>. Then the mean of <span class="math inline">\(w\)</span> is 0, so that, by definition, <span class="math inline">\(\mathbb{E}(w^2)\)</span> is its variance, <span class="math inline">\(\mathbb{V}(w)\)</span>. The variance of a uniform distribution over the interval <span class="math inline">\([a,b]\)</span> is given by <span class="math inline">\(\frac{(b-a)^2}{12}\)</span>, from which we get <span class="math inline">\(\mathbb{V}(w) = \frac{R^2}{3}\)</span>. Substituting this into our equation we get: <span class="math display">\[n\frac{R^2}{3} = 1\]</span></p>
<p>So that: <span class="math display">\[R = \frac{\sqrt{3}}{\sqrt{n}}\]</span></p>
<p>This is a nice result because it is the Xavier-Glorot initialization for a square weight matrix, yet was motivated by a different idea. The Xavier-Glorot initialization, introduced by Glorot and Bengio (2010), has proven to be an effective weight initialization prescription in practice. More generally, the Xavier-Glorot prescription applies to m-by-n weight matrices used in a layer that has an activation function whose derivative is near one at the origin (like tanh), and says that we should initialize our weights according to a uniform distribution of the interval: <span class="math display">\[[-\frac{\sqrt{6}}{\sqrt{m+n}},+\frac{\sqrt{6}}{\sqrt{m+n}}]\]</span></p>
<p>We saw above that good weight initializations are crucial, but this only impacts the start of training.</p>
<h2 id="written-memories-the-intuition-behind-lstms">Written memories: the intuition behind LSTMs</h2>
<p>Very much like the messages passed by children playing a game of broken telephone, information is morphed by RNN cells and the original message is lost. A small change in the original message may not have made any difference in the final message, or it may have resulted in something completely different.</p>
<p>How can we protect the integrity of messages? This is the fundamental principle of LSTMs: to ensure the integrity of our messages in the real world, we write them down. Writing is <em><strong>a delta to the current state</strong></em>: it is an act of creation (pen on paper) or destruction (carving in stone); the subject itself does not morph when you write on it and the error gradient on the backward-pass is constant.</p>
<p>This is precisely what was proposed by the landmark paper of Hocreiter and Schmidhuber (1997), which introduced the LSTM. They asked: “how can we achieve constant error flow through a single unit with a single connection to itself [i.e., a single piece of isolated information]?”</p>
<p>The answer, quite simply, is to avoid information morphing: changes to the state of an LSTM are explicitly written in, by an explicit addition or subtraction, so that each element of the state stays constant without outside interference: “the unit’s activation has to remain constant … this will be ensured by using the identity function”.</p>
<span class="math display">\[\begin{equation}\begin{split}
f_t &amp;= \sigma (W_f \cdot [h_{t-1}, x_t] + b_f)\\\\
i_t &amp;= \sigma (W_i \cdot [h_{t-1}, x_t] + b_i)\\\\
\tilde{C}_t &amp;= tanh(W_c \cdot [h_{t-1}, x_t] +b_c)\\\\
C_t &amp;= f_t \ast C_{t-1} + i_t \ast \tilde{C}_t \\\\
o_t &amp;= \sigma (W_o \cdot [h_{t-1}, x_t] + b_o)\\\\
h_t &amp;= o_t \ast tanh(C_t)
\end{split}\end{equation}\]</span>
<p>Suppose we have calculated the value of <span class="math inline">\(\frac{\partial L}{C_{t+k}}\)</span>, then: <span class="math display">\[\frac{\partial L}{C_t} = \frac{\partial L}{C_{t+k}} \odot f_{t+k-1} \odot f_{t+k-2} ... \odot f_{t}\]</span> Except for the very first term, the vanishing problem still exist.</p>
<h2 id="different-between-tanh-and-sigmoid-function">Different Between Tanh and Sigmoid Function</h2>
<ul>
<li>Sigmoid function have domain of all real numbers, ranging from 0 to 1, campared with Tanh function whose domain ranging from -1 to 1. The problem of Sigmoid is that the activation value is always positive, which give rise to the phenomenon that the derivative of weights are always all positive or all negative.</li>
<li>When a sigmoidal activation function must be used, the hyperbolic tangent activation function typically performs better than the logistic sigmoid. It <em><strong>resembles the identity function more closely</strong></em>, in the sense that <span class="math inline">\(tanh(0) = 0\)</span> while <span class="math inline">\(\sigma(0) = \frac{1}{2}\)</span>. Because tanh is similar to the identity function near 0, training a deep neural network <span class="math inline">\(\hat{y} = W^T tanh(U^T tanh(V^TX))\)</span> resembles training a linear model <span class="math inline">\(\hat{y} = W^TU^TV^TX\)</span> so long as the activations of the network can be kept small. This makes training the tanh network easier.</li>
</ul>
<h1 id="reference">Reference</h1>
<p><a href="https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html#written-memories-the-intuition-behind-lstms" target="_blank" rel="external">Written memories the intuition behind lstms</a> <a href="http://www.deeplearningbook.org/contents/mlp.html" target="_blank" rel="external">Deep Learning Chap6</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/02/2017-09-02RNN for NLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/02/2017-09-02RNN for NLP/" itemprop="url">RNN for NLP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-02T17:49:17+10:00">
                2017-09-02
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DL/" itemprop="url" rel="index">
                    <span itemprop="name">DL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>When training LSTM networks, Jozefowicz et al. [2015] strongly recommend to always initialize the bias term of the forget gate to be close to one.</p>
<p>Applying dropout to RNNs can be a bit tricky, that is, the dropout masks are sampled once per sequence, and not once per time step.</p>
<p>For longer sentences classification, Li et al.[2015] found it useful to use a hierarchical architecture, in which the sentence is split into smaller spans based on punctuation. Then, each span is fed into a forward and a backward RNN. Sequence of resulting vectors (one for each span) are then fed into an RNN acceptor.</p>
<p>To represent a word, except for general word embedding method like word2vec, we can use two character-level RNNs. For a word <span class="math inline">\(w\)</span>, made of characters <span class="math inline">\(c_1,c_2,...,c_l\)</span>, we will map each character into a corresponding embedding vector <span class="math inline">\(\mathbf{c}_i\)</span>. The word will then be encoded using a forward RNN and a reverse RNN over the characters. These RNNs can then either replace the word embedding vector, or, better yet, be concatenated.</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/01/2017-09-01CNN for NLP/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/09/01/2017-09-01CNN for NLP/" itemprop="url">CNN for NLP</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-01T14:45:30+10:00">
                2017-09-01
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/DL/" itemprop="url" rel="index">
                    <span itemprop="name">DL</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>A convolutional neural network is designed to identify indicative local predictors in a large structure, and to combine them to produce a fixed size vector representation of the structure, capturing the local aspects that are most informative for the prediction task at hand. For instance, the convolutional architecture will identy n-grams that are predictive for the task at hand, without the need to pre-specify an embedding vector for each possible n-gram.<br>
The convolutional architecture also allows to share predictive behavior between n-grams that share similar components, even if the exact n-gram was never seen at test time.<br>
It could be expanded into a hierarchy of convolution layers, each one effectively looking at longer range of n-grams in the sentence.</p>
<center>
<img src="/images/2017-09-01CNN%20for%20NLP/single%20layer%20cnn.png">
</center>
The graph above is an example of only one convolution and max-pooling for sentence classification whose filters have different sizes. Without the pooling layer and scarifice the diverse filter sizes, we can generalize CNN model to hierarchical form.
<center>
<img src="/images/2017-09-01CNN%20for%20NLP/hierarchical%20cnn.png">
</center>
<h3 id="about-channels">About Channels</h3>
<p>When applying a convolution to an image in computer vision, it is common to apply a different set of filters to each channel, and then combine the three resulting vectors into a single vector. For text processing, we can still have multiple channels. For example, one channel will be the <em><strong>sequence of words</strong></em>, one channel will be the sequence of the corresponding <em><strong>POS</strong></em> tags and one will be the sequence of the corresponding <em><strong>positions</strong></em>. These three views can then be combined either by summation or by concatenation.</p>
<h3 id="feature-hashing">Feature Hashing</h3>
<p>There is no need to pre-compute vocabulary-to-index mapping, instead, allocate an embedding matrix <em><span class="math inline">\(E\)</span></em> with N rows. N should be sufficiently large, but no prohibitive. When a k-gram is seen in training, we assign it to a row in <em><span class="math inline">\(E\)</span></em> by applying hash function that will deterministically map it into a number in the range <span class="math inline">\([1,N]\)</span>. Then use the corresponding row as the embedding vector.</p>
<h3 id="dilated-convolution-architecture">Dilated Convolution Architecture</h3>
<p>A recent development (e.g. see paper by Fisher Yu and Vladlen Koltun) is to introduce one more hyperparameter to the CONV layer called the dilation. The normal CONV filters are contiguous. However, it’s possible to have filters that have spaces between each cell, called dilation.</p>
<p>It’s perhaps useful to first note why vanilla convolutions struggle to integrate global context. Consider a purely convolutional network composed of layers of <span class="math inline">\(k \times k\)</span> convolutions, without pooling. It is easy to see that size of the receptive field of each unit — the block of pixels which can influence its activation — is <span class="math inline">\(l \ast (k-1) + k\)</span>, where l is the layer index. So the effective receptive field of units can only grow linearly with layers. This is very limiting, especially for high-resolution input images.</p>
<p>As an example, in one dimension a filter w of size 3 would compute over input <span class="math inline">\(x\)</span> the following: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">w[0]*x[0] + w[1]*x[1] + w[2]*x[2]</div></pre></td></tr></table></figure></p>
<p>This is dilation of 0. For dilation 1 the filter would instead compute: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">w[0]*x[0] + w[1]*x[2] + w[2]*x[4]</div></pre></td></tr></table></figure></p>
<p>In other words there is a gap of 1 between the applications. This can be very useful in some settings to use in conjunction with 0-dilated filters because it allows you to merge spatial information across the inputs much more agressively with fewer layers. For example, if you stack two 3x3 CONV layers on top of each other then you can convince yourself that the neurons on the 2nd layer are a function of a 5x5 patch of the input (we would say that the effective receptive field of these neurons is 5x5). If we use dilated convolutions then this effective receptive field would grow much quicker.</p>
<h1 id="reference">Reference</h1>
<ol style="list-style-type: decimal">
<li>http://cs231n.github.io/convolutional-networks/</li>
<li>http://www.wildml.com/2015/11/understanding-convolutional-neural-networks-for-nlp/</li>
<li>Neural Network Methods in Natural Language Processing Chapter 13</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/31/2017-08-31Batch Normalization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/31/2017-08-31Batch Normalization/" itemprop="url">Batch Normalization</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-31T22:00:34+10:00">
                2017-08-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Intuition/" itemprop="url" rel="index">
                    <span itemprop="name">Intuition</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Batch normalization makes your hyperparameter search problem much easier, makes the neural network much more robust to the choice of hyperparameters, there’s a much bigger range of hyperparameters that work well, and will also enable you to much more easily train even very deep networks. Normalizing the input feature values can turn the contours of the learning problem from something that might be very elongated to something that is more round and easier for an algorithm like gradient descend to optimize. So, can we apply normalization to the intermediate layers? This is where batch normalization inspired from!</p>
<strong>Batch Normalization Algorithm </strong><br>
Given some intermediate values in a neural network, <span class="math inline">\({z^{(1)},z^{(2)},...,z^{(m)}}\)</span>
<span class="math display">\[\begin{equation}\begin{split}
\mu = \frac{1}{m}\Sigma_i z^{(i)}\\\\
\sigma^2 = \frac{1}{m}\Sigma_i (z^{(i)} - \mu)^2\\\\
z^{(i)}_{norm} = \frac{(z^{(i)} - \mu)}{\sqrt{\sigma^2 + \epsilon}}\\\\
\widehat{z}^{(i)} = \gamma z^{(i)}_{norm} + \beta
\end{split}\end{equation}\]</span>
<p>With batch normalization, the entire computational process should be: <span class="math display">\[X \stackrel{W^{[1]},b^{[1]}}{\longrightarrow}Z^{[1]}\stackrel{\beta^{[1]},\gamma^{[1]}}{\longrightarrow}\widehat{Z}^{[1]}\rightarrow A^{[1]} \stackrel{W^{[2]},b^{[2]},BN}{\longrightarrow} \widehat{Z}^{[2]} \rightarrow \cdot\cdot\cdot\]</span> The training parameters includes: <span class="math inline">\(w^{[1]}, b^{[1]}, ... ,w^{[l]}, b^{[l]}\)</span> and <span class="math inline">\(\beta^{[1]}, \gamma^{[1]}, ... ,\beta^{[l]}, \gamma^{[l]}\)</span> We should notice that, b can be eliminated due to that BN zeros out the mean.</p>
<p>The intuition behind is that:<br>
- Batch Normalization reduces the problem of the input values changing, it really causes these values to become stable, so that the later layers of the neural network has more firm ground to stand on.<br>
- Due to mini-batch, it adds some noise to each hidden layers’ activations, and produces some light regularization impact.</p>
<p>At test time, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are estimated by using exponentially weighted average across mini-batch. For a specific layer <span class="math inline">\(l\)</span>, we use EWA to keep track of the values of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> of layer <span class="math inline">\(l\)</span> during training which will be used at test time.</p>
<p>For CNN model, for a mini-batch of size <span class="math inline">\(m\)</span> and feature maps of size <span class="math inline">\(p \times q\)</span>, we use the effecive mini-batch of size <span class="math inline">\(m&#39; = m \cdot pq\)</span>. We learn a pair of parameters <span class="math inline">\(\gamma^{(k)}\)</span> and <span class="math inline">\(\beta^{(k)}\)</span> per feature map, rather than per activation.</p>
<h1 id="reference">Reference</h1>
<p>Andrew Ng’s Deep Learning Course</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/08/31/2017-08-31Optimization Methods in Deep Learning/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2017/08/31/2017-08-31Optimization Methods in Deep Learning/" itemprop="url">Optimization Methods in Deep Learning</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-08-31T15:56:48+10:00">
                2017-08-31
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Intuition/" itemprop="url" rel="index">
                    <span itemprop="name">Intuition</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="why-gradient-descend-works">Why Gradient Descend Works?</h1>
Gradient Descend is the fundamental optimization method to learn parameters. To illustrate why it works, let’s take the simple example $f(x) = (x - 1)^2 $ to gain some intuition.
<center>
<img src="/images/2017-08-31Optimization%20Methods%20in%20Deep%20Learning/GD_intuition.png">
</center>
<ul>
<li>For point <span class="math inline">\(x=3\)</span>, <span class="math inline">\(f&#39;(x)=4&gt;0\)</span></li>
<li>For point <span class="math inline">\(x=-1\)</span>, <span class="math inline">\(f&#39;(x)=-4&lt;0\)</span></li>
</ul>
<p>If we want to decreace the value of <span class="math inline">\(f(x)\)</span>:<br>
- For point <span class="math inline">\(x=3\)</span>, we need to move a small step towards the opposite direction of <span class="math inline">\(f&#39;(x=3)\)</span><br>
- For point <span class="math inline">\(x=-1\)</span>, we need to move a samll step towards the opposite direction of <span class="math inline">\(f&#39;(x=-1)\)</span></p>
<p>So, if we want to descreace the value of a given function, we just move a small step towards the opposite direction of the function’s gradient.</p>
<h1 id="the-difference-among-gd-sgd-batch-sgd">The difference among GD, SGD, Batch-SGD</h1>
For <em><strong>Gradient Descend</strong></em>, take gradient steps with respect to all training examples on each step:
<center>
<img src="/images/2017-08-31Optimization%20Methods%20in%20Deep%20Learning/SGD_GD.png">
</center>
For <em><strong>Stochastic Gradient Descend</strong></em>, take gradient steps with respect to just one random training example on each step:
<center>
<img src="/images/2017-08-31Optimization%20Methods%20in%20Deep%20Learning/SGD_BGD.png">
</center>
<p>For <em><strong>Batch Gradient Descend</strong></em>, take gradient steps with respect to <span class="math inline">\(m\)</span> training examples on each step.</p>
<h1 id="momentum">Momentum</h1>
<p>Because mini-batch gradient descent makes a parameter update after seeing just a subset of examples, the direction of the update has some variance, and so the path taken by mini-batch gradient descent will <em><strong>oscillate</strong></em> toward convergence. Using momentum can reduce these oscillations.</p>
<p>Momentum takes into account the past gradients to smooth out the update. We will store the <em><strong>direction</strong></em> of the previous gradients in the variable <span class="math inline">\(v\)</span>. Formally, this will be the exponentially weighted average of the gradient on previous steps. You can also think of <span class="math inline">\(v\)</span> as the <em><strong>velocity</strong></em> of a ball rolling downhill, building up speed (and momentum) according to the direction of the gradient/slope of the hill.</p>
<center>
<img src="/images/2017-08-31Optimization%20Methods%20in%20Deep%20Learning/Momentum.png">
</center>
<p>The red arrows shows the direction taken by one step of mini-batch gradient descent with momentum. The blue points show the direction of the gradient (with respect to the current mini-batch) on each step. Rather than just following the gradient, we let the gradient influence <span class="math inline">\(v\)</span> and then take a step in the direction of <span class="math inline">\(v\)</span>.</p>
<p>First, let’s gain some intuition from <em><strong>Exponentially Weighted Average</strong></em>.<br>
Let <span class="math inline">\(v\)</span> denote the variable for later use, and <span class="math inline">\(\theta\)</span> is the current observation <span class="math display">\[v_0 = 0\]</span> <span class="math display">\[v_1 = \beta v_0 + (1-\beta)\theta_1\]</span> <span class="math display">\[v_2 = \beta v_1 + (1-\beta)\theta_2\]</span> <span class="math display">\[.\]</span> <span class="math display">\[.\]</span> <span class="math display">\[.\]</span></p>
<p><span class="math display">\[v_t = \beta v_{t-1} + (1-\beta)\theta_t\]</span></p>
The intuition behind the above equation is that:
<span class="math display">\[\begin{equation}\begin{split}
v_t &amp;= \beta v_{t-1} + (1-\beta)\theta_t\\\\
&amp;= (1 - \beta)\theta_t + \beta(\beta v_{t-2} + (1-\beta)\theta_{t-1})\\\\
&amp;= (1-\beta)\theta_t + \beta(1-\beta)\theta_{t-1} + \beta^2v_{t-2}\\\\
&amp;= (1-\beta)\theta_t + \beta(1-\beta)\theta_{t-1} + \beta^2(1-\beta)\theta_{t-2} + ...
\end{split}\end{equation}\]</span>
<p>It’s just the exponentially weighted average of all the observations.</p>
<p>Inspired by the above equations, we define the gradient descent with momentum as follows: <span class="math display">\[v_{d_w} = \beta v_{d_w} + (1 - \beta)d_w\]</span> <span class="math display">\[v_{d_b} = \beta v_{d_b} + (1 - \beta)d_b\]</span> <span class="math display">\[w := w - \alpha v_{d_w}\]</span> <span class="math display">\[b := w - \alpha v_{d_b}\]</span></p>
<p>How do you choose <span class="math inline">\(\beta\)</span>?<br>
- The larger the momentum <span class="math inline">\(\beta\)</span> is, the smoother the update because the more we take the past gradients into account. But if <span class="math inline">\(\beta\)</span> is too big, it could also smooth out the updates too much.<br>
- Common values for <span class="math inline">\(\beta\)</span> range from 0.8 to 0.999. If you don’t feel inclined to tune this, <span class="math inline">\(\beta = 0.9\)</span> is often a reasonable default.<br>
- Tuning the optimal <span class="math inline">\(\beta\)</span> for your model might need trying several values to see what works best in term of reducing the value of the cost function.</p>
<p>Example code: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">def update_parameters_with_momentum(parameters, grads, v, beta, learning_rate):</div><div class="line">    <span class="string">""</span><span class="string">"</span></div><div class="line"><span class="string">    Update parameters using Momentum</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    parameters -- python dictionary containing your parameters:</span></div><div class="line"><span class="string">                    parameters['W' + str(l)] = Wl</span></div><div class="line"><span class="string">                    parameters['b' + str(l)] = bl</span></div><div class="line"><span class="string">    grads -- python dictionary containing your gradients for each parameters:</span></div><div class="line"><span class="string">                    grads['dW' + str(l)] = dWl</span></div><div class="line"><span class="string">                    grads['db' + str(l)] = dbl</span></div><div class="line"><span class="string">    v -- python dictionary containing the current velocity:</span></div><div class="line"><span class="string">                    v['dW' + str(l)] = ...</span></div><div class="line"><span class="string">                    v['db' + str(l)] = ...</span></div><div class="line"><span class="string">    beta -- the momentum hyperparameter, scalar</span></div><div class="line"><span class="string">    learning_rate -- the learning rate, scalar</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></div><div class="line"><span class="string">    v -- python dictionary containing your updated velocities</span></div><div class="line"><span class="string">    "</span><span class="string">""</span></div><div class="line"></div><div class="line">    L = len(parameters) // 2 <span class="comment"># number of layers in the neural networks</span></div><div class="line">    </div><div class="line">    <span class="comment"># Momentum update for each parameter</span></div><div class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</div><div class="line">        </div><div class="line">        <span class="comment"># compute velocities</span></div><div class="line">        v[<span class="string">"dW"</span> + str(l+1)] = beta * v[<span class="string">"dW"</span> + str(l+1)] + (1-beta) * grads[<span class="string">"dW"</span> + str(l+1)]</div><div class="line">        v[<span class="string">"db"</span> + str(l+1)] = beta * v[<span class="string">"db"</span> + str(l+1)] + (1-beta) * grads[<span class="string">"db"</span> + str(l+1)]</div><div class="line">        <span class="comment"># update parameters</span></div><div class="line">        parameters[<span class="string">"W"</span> + str(l+1)] = parameters[<span class="string">"W"</span> + str(l+1)] - learning_rate * v[<span class="string">"dW"</span> + str(l+1)]</div><div class="line">        parameters[<span class="string">"b"</span> + str(l+1)] = parameters[<span class="string">"b"</span> + str(l+1)] - learning_rate * v[<span class="string">"db"</span> + str(l+1)]</div><div class="line">        </div><div class="line">    <span class="built_in">return</span> parameters, v</div></pre></td></tr></table></figure></p>
<h1 id="rmsprop">RMSprop</h1>
<p>RMSprop, which stands for root mean square prop, is also inspired by the <em>Exponentially Weighted Average</em>. The algorithm is:<br>
<span class="math display">\[s_{d_w} = \beta s_{d_w} + (1 - \beta)d_w^2\]</span> <span class="math display">\[s_{d_b} = \beta s_{d_b} + (1 - \beta)d_b^2\]</span> <span class="math display">\[w := w - \alpha \frac{d_w}{\sqrt{s_{d_w}}}\]</span> <span class="math display">\[b := b - \alpha \frac{d_b}{\sqrt{s_{d_b}}}\]</span></p>
<p>The intuition behind is also to damp out the huge oscillations. Let’s say <span class="math inline">\(d_w\)</span> is larger than <span class="math inline">\(d_b\)</span>, then <span class="math inline">\(s_{d_w}\)</span> is also larger than <span class="math inline">\(s_{d_b}\)</span>. When we update parameters <span class="math inline">\(w\)</span> and <span class="math inline">\(b\)</span>, <span class="math inline">\(d_w\)</span> is divided by a relatively larger number than <span class="math inline">\(d_b\)</span> whcih helps to damp out oscillations.</p>
<p>The common choice of <span class="math inline">\(\beta\)</span> is 0.999.</p>
<p>Example code: <figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div></pre></td><td class="code"><pre><div class="line">def update_parameters_with_RMSprop(parameters, grads, s, beta, learning_rate):</div><div class="line">    <span class="string">""</span><span class="string">"</span></div><div class="line"><span class="string">    Update parameters using RMSprop</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    parameters -- python dictionary containing your parameters:</span></div><div class="line"><span class="string">                    parameters['W' + str(l)] = Wl</span></div><div class="line"><span class="string">                    parameters['b' + str(l)] = bl</span></div><div class="line"><span class="string">    grads -- python dictionary containing your gradients for each parameters:</span></div><div class="line"><span class="string">                    grads['dW' + str(l)] = dWl</span></div><div class="line"><span class="string">                    grads['db' + str(l)] = dbl</span></div><div class="line"><span class="string">    s -- python dictionary containing the current squared gradient:</span></div><div class="line"><span class="string">                    s['dW' + str(l)] = ...</span></div><div class="line"><span class="string">                    s['db' + str(l)] = ...</span></div><div class="line"><span class="string">    beta -- the RMSprop hyperparameter, scalar</span></div><div class="line"><span class="string">    learning_rate -- the learning rate, scalar</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></div><div class="line"><span class="string">    s -- python dictionary containing your updated squared gradient</span></div><div class="line"><span class="string">    "</span><span class="string">""</span></div><div class="line"></div><div class="line">    L = len(parameters) // 2 <span class="comment"># number of layers in the neural networks</span></div><div class="line">    </div><div class="line">    <span class="comment"># RMSprop update for each parameter</span></div><div class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</div><div class="line">        </div><div class="line">        <span class="comment"># compute current squared gradient</span></div><div class="line">        s[<span class="string">"dW"</span> + str(l+1)] = beta * s[<span class="string">"dW"</span> + str(l+1)] + (1-beta) * grads[<span class="string">"dW"</span> + str(l+1)] ** 2</div><div class="line">        s[<span class="string">"db"</span> + str(l+1)] = beta * s[<span class="string">"db"</span> + str(l+1)] + (1-beta) * grads[<span class="string">"db"</span> + str(l+1)] ** 2</div><div class="line">        <span class="comment"># update parameters</span></div><div class="line">        parameters[<span class="string">"W"</span> + str(l+1)] = parameters[<span class="string">"W"</span> + str(l+1)] - learning_rate * s[<span class="string">"dW"</span> + str(l+1)] / np.sqrt(s[<span class="string">"dW"</span> + str(l+1)])</div><div class="line">        parameters[<span class="string">"b"</span> + str(l+1)] = parameters[<span class="string">"b"</span> + str(l+1)] - learning_rate * s[<span class="string">"db"</span> + str(l+1)] / np.sqrt(s[<span class="string">"db"</span> + str(l+1)])</div><div class="line">        </div><div class="line">    <span class="built_in">return</span> parameters, s</div></pre></td></tr></table></figure></p>
<h1 id="adam">Adam</h1>
<p>Adam is one of the most effective optimization algorithms for training neural networks. It combines ideas from RMSProp (described in lecture) and Momentum. The update rule is, for <span class="math inline">\(l = 1,...L\)</span>: <span class="math display">\[v_{dW^{[l]}} = \beta_1 v_{dW^{[l]}} + (1 - \beta_1) \frac{\partial Cost}{\partial W^{[l]}}\]</span> <span class="math display">\[v^{corrected}_{dW^{[l]}} = \frac{v_{dW^{[l]}}}{1 - (\beta_1)^t}\]</span> <span class="math display">\[s_{dW^{[l]}} = \beta_2 s_{dW^{[l]}} + (1 - \beta_2) (\frac{\partial Cost}{\partial W^{[l]}})^2\]</span> <span class="math display">\[s^{corrected}_{dW^{[l]}} = \frac{s_{dW^{[l]}}}{1 - (\beta_2)^t}\]</span> <span class="math display">\[W^{[L]} = W^{[L]} - \alpha \frac{v^{corrected}_{dW^{[l]}}}{\sqrt{s^{corrected}_{dW^{[l]}} + \epsilon}}\]</span></p>
<p>where:<br>
- t counts the number of steps taken of Adam<br>
- L is the number of layers<br>
- <span class="math inline">\(\beta_1\)</span> and <span class="math inline">\(\beta_2\)</span> are hyperparameters that control the two exponentially weighted averages.<br>
- <span class="math inline">\(\alpha\)</span> is the learning rate<br>
- <span class="math inline">\(\epsilon\)</span> is a very small number to avoid dividing by zero.</p>
<p>The common choice of hyperparameters s <span class="math inline">\(\beta_1 = 0.9. \beta_2 = 0.999, \epsilon = 1e-8\)</span></p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line">def update_parameters_with_adam(parameters, grads, v, s, t, learning_rate = 0.01,</div><div class="line">                                beta1 = 0.9, beta2 = 0.999,  epsilon = 1e-8):</div><div class="line">    <span class="string">""</span><span class="string">"</span></div><div class="line"><span class="string">    Update parameters using Adam</span></div><div class="line"><span class="string">    </span></div><div class="line"><span class="string">    Arguments:</span></div><div class="line"><span class="string">    parameters -- python dictionary containing your parameters:</span></div><div class="line"><span class="string">                    parameters['W' + str(l)] = Wl</span></div><div class="line"><span class="string">                    parameters['b' + str(l)] = bl</span></div><div class="line"><span class="string">    grads -- python dictionary containing your gradients for each parameters:</span></div><div class="line"><span class="string">                    grads['dW' + str(l)] = dWl</span></div><div class="line"><span class="string">                    grads['db' + str(l)] = dbl</span></div><div class="line"><span class="string">    v -- Adam variable, moving average of the first gradient, python dictionary</span></div><div class="line"><span class="string">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></div><div class="line"><span class="string">    learning_rate -- the learning rate, scalar.</span></div><div class="line"><span class="string">    beta1 -- Exponential decay hyperparameter for the first moment estimates </span></div><div class="line"><span class="string">    beta2 -- Exponential decay hyperparameter for the second moment estimates </span></div><div class="line"><span class="string">    epsilon -- hyperparameter preventing division by zero in Adam updates</span></div><div class="line"><span class="string"></span></div><div class="line"><span class="string">    Returns:</span></div><div class="line"><span class="string">    parameters -- python dictionary containing your updated parameters </span></div><div class="line"><span class="string">    v -- Adam variable, moving average of the first gradient, python dictionary</span></div><div class="line"><span class="string">    s -- Adam variable, moving average of the squared gradient, python dictionary</span></div><div class="line"><span class="string">    "</span><span class="string">""</span></div><div class="line">    </div><div class="line">    L = len(parameters) // 2                 <span class="comment"># number of layers in the neural networks</span></div><div class="line">    v_corrected = &#123;&#125;                         <span class="comment"># Initializing first moment estimate, python dictionary</span></div><div class="line">    s_corrected = &#123;&#125;                         <span class="comment"># Initializing second moment estimate, python dictionary</span></div><div class="line">    </div><div class="line">    <span class="comment"># Perform Adam update on all parameters</span></div><div class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> range(L):</div><div class="line">        <span class="comment"># Moving average of the gradients. Inputs: "v, grads, beta1". Output: "v".</span></div><div class="line">        v[<span class="string">"dW"</span> + str(l+1)] = beta1 * v[<span class="string">"dW"</span> + str(l+1)] + (1 - beta1) * grads[<span class="string">"dW"</span> + str(l+1)]</div><div class="line">        v[<span class="string">"db"</span> + str(l+1)] = beta1 * v[<span class="string">"db"</span> + str(l+1)] + (1 - beta1) * grads[<span class="string">"db"</span> + str(l+1)]</div><div class="line"></div><div class="line">        <span class="comment"># Compute bias-corrected first moment estimate. Inputs: "v, beta1, t". Output: "v_corrected".</span></div><div class="line">        v_corrected[<span class="string">"dW"</span> + str(l+1)] = v[<span class="string">"dW"</span> + str(l+1)] / (1 - beta1 ** t)</div><div class="line">        v_corrected[<span class="string">"db"</span> + str(l+1)] = v[<span class="string">"db"</span> + str(l+1)] / (1 - beta1 ** t)</div><div class="line"></div><div class="line">        <span class="comment"># Moving average of the squared gradients. Inputs: "s, grads, beta2". Output: "s".</span></div><div class="line">        s[<span class="string">"dW"</span> + str(l+1)] = beta2 * s[<span class="string">"dW"</span> + str(l+1)] + (1 - beta2) * grads[<span class="string">"dW"</span> + str(l+1)] ** 2</div><div class="line">        s[<span class="string">"db"</span> + str(l+1)] = beta2 * s[<span class="string">"db"</span> + str(l+1)] + (1 - beta2) * grads[<span class="string">"db"</span> + str(l+1)] ** 2</div><div class="line"></div><div class="line">        <span class="comment"># Compute bias-corrected second raw moment estimate. Inputs: "s, beta2, t". Output: "s_corrected".</span></div><div class="line">        s_corrected[<span class="string">"dW"</span> + str(l+1)] = s[<span class="string">"dW"</span> + str(l+1)] / (1 - beta2 ** t)</div><div class="line">        s_corrected[<span class="string">"db"</span> + str(l+1)] = s[<span class="string">"db"</span> + str(l+1)] / (1 - beta2 ** t)</div><div class="line"></div><div class="line">        <span class="comment"># Update parameters. Inputs: "parameters, learning_rate, v_corrected, s_corrected, epsilon". Output: "parameters".</span></div><div class="line">        parameters[<span class="string">"W"</span> + str(l+1)] = parameters[<span class="string">"W"</span> + str(l+1)] - learning_rate * v_corrected[<span class="string">"dW"</span> + str(l+1)] / np.sqrt(s_corrected[<span class="string">"dW"</span> + str(l+1)] + epsilon)</div><div class="line">        parameters[<span class="string">"b"</span> + str(l+1)] = parameters[<span class="string">"b"</span> + str(l+1)] - learning_rate * v_corrected[<span class="string">"db"</span> + str(l+1)] / np.sqrt(s_corrected[<span class="string">"db"</span> + str(l+1)] + epsilon)</div><div class="line"></div><div class="line">    <span class="built_in">return</span> parameters, v, s</div></pre></td></tr></table></figure>
<h1 id="reference">Reference</h1>
<p>Andrew Ng’s deep learning course</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel sidebar-panel-active">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Ember" />
          <p class="site-author-name" itemprop="name">Ember</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ember</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">Theme &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script>



  


  








  








  





  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
