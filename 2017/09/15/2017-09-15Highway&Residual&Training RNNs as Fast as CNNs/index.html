<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="RNN,DL," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="Highway Network Highway networks allow unimpeded information flow across several layers on information highways. A plain feedforward neural network typically consists of \(L\) layers where the \(l^{th">
<meta name="keywords" content="RNN,DL">
<meta property="og:type" content="article">
<meta property="og:title" content="Highway Network &amp; Residual Network &amp; Training RNNs as Fast as CNNs">
<meta property="og:url" content="http://yoursite.com/2017/09/15/2017-09-15Highway&Residual&Training RNNs as Fast as CNNs/index.html">
<meta property="og:site_name" content="EmberNLP">
<meta property="og:description" content="Highway Network Highway networks allow unimpeded information flow across several layers on information highways. A plain feedforward neural network typically consists of \(L\) layers where the \(l^{th">
<meta property="og:locale" content="en">
<meta property="og:updated_time" content="2017-09-18T09:57:44.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Highway Network &amp; Residual Network &amp; Training RNNs as Fast as CNNs">
<meta name="twitter:description" content="Highway Network Highway networks allow unimpeded information flow across several layers on information highways. A plain feedforward neural network typically consists of \(L\) layers where the \(l^{th">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/09/15/2017-09-15Highway&Residual&Training RNNs as Fast as CNNs/"/>





  <title>Highway Network & Residual Network & Training RNNs as Fast as CNNs | EmberNLP</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">EmberNLP</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/15/2017-09-15Highway&Residual&Training RNNs as Fast as CNNs/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Highway Network & Residual Network & Training RNNs as Fast as CNNs</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-15T15:15:33+10:00">
                2017-09-15
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="highway-network">Highway Network</h1>
<p>Highway networks allow unimpeded information flow across several layers on information highways.</p>
<p>A plain feedforward neural network typically consists of <span class="math inline">\(L\)</span> layers where the <span class="math inline">\(l^{th}\)</span> layer <span class="math inline">\((l \in \{ 1,2,...,L \})\)</span> applies a non-linear transform <span class="math inline">\(H\)</span> (parameterized by <span class="math inline">\(\mathbf{W_{H,l}}\)</span>) on its input <span class="math inline">\(\mathbf{x_l}\)</span> to produce its output <span class="math inline">\(\mathbf{y_l}\)</span>. Thus, <span class="math inline">\(\mathbf{x_1}\)</span> is the input to the network and <span class="math inline">\(\mathbf{y_L}\)</span> is the networkâ€™s output. Omitting the layer index and biases for clarity,</p>
<span class="math display">\[\begin{equation}\begin{split}
\mathbf{y} = H (\mathbf{x}, \mathbf{W_H})
\end{split}\end{equation}\]</span>
<p><span class="math inline">\(H\)</span> is usually an affine transform followed by a non-linear activation function, but in general it may take other forms.</p>
<p>For a highway network, the author defined two non-linear transforms <span class="math inline">\(T (\mathbf{x}, \mathbf{W_T})\)</span> and <span class="math inline">\(C (\mathbf{x}, \mathbf{W_C})\)</span> such that</p>
<span class="math display">\[\begin{equation}\begin{split}
\mathbf{y} = H (\mathbf{x}, \mathbf{W_H}) \cdot T (\mathbf{x}, \mathbf{W_T}) + \mathbf{x} \cdot C (\mathbf{x}, \mathbf{W_C})
\end{split}\end{equation}\]</span>
<p><span class="math inline">\(T\)</span> is the <em><strong>transform gate</strong></em> and <span class="math inline">\(C\)</span> is the <em><strong>carry gate</strong></em>, since they express how much of the output is produced by transforming the input and carrying it, respectively. For simplicity, in this paper, <span class="math inline">\(C = 1 âˆ’ T\)</span> , giving</p>
<span class="math display">\[\begin{equation}\begin{split}
\mathbf{y} = H (\mathbf{x}, \mathbf{W_H}) \cdot T (\mathbf{x}, \mathbf{W_T}) + \mathbf{x} \cdot (1 - T (\mathbf{x}, \mathbf{W_T}))
\end{split}\end{equation}\]</span>
<p>We should notice that the dimensionality of <span class="math inline">\(\mathbf{x}\)</span>, <span class="math inline">\(\mathbf{y}\)</span>, <span class="math inline">\(H (\mathbf{x}, \mathbf{W_H})\)</span> and <span class="math inline">\(T (\mathbf{x}, \mathbf{W_T})\)</span> must be the same for above Equation (3) to be valid. Also note that this re-parametrization of the layer transformation is much more flexible than Equation (1). In particular, observe that</p>
<span class="math display">\[\begin{equation}
\mathbf{y} =
\left\{
\begin{aligned}
&amp;\mathbf{x}, &amp;if \space T (\mathbf{x}, \mathbf{W_T}) = \mathbf{0} \\
&amp;H (\mathbf{x}, \mathbf{W_H}), &amp;if \space T (\mathbf{x}, \mathbf{W_T}) = \mathbf{1}\\
\end{aligned}
\right.
\end{equation}\]</span>
<p>Thus, depending on the output of the transform gates, a highway layer can smoothly vary its behavior between that of a plain layer and that of a layer which simply passes its inputs through. Just as a plain layer consists of multiple computing units such that the <span class="math inline">\(i^{th}\)</span> unit computes <span class="math inline">\(y_i = H_i (\mathbf{x})\)</span>, a highway network consists of multiple blocks such that the <span class="math inline">\(i^{th}\)</span> block computes a block state <span class="math inline">\(H_i (\mathbf{x})\)</span> and transform gate output <span class="math inline">\(T_i (\mathbf{x})\)</span>. Finally, it produces the block output <span class="math inline">\(y_i =H_i (\mathbf{x}) \ast T_i (\mathbf{x}) + x_i \ast (1âˆ’T_i (\mathbf{x}))\)</span>, which is connected to the next layer.</p>
<p><strong>In other words, Highway network treats every layer from layerwise to blockwise.</strong></p>
<h1 id="residual-network">Residual Network</h1>
<p>In this paper, the author addressed the degradation problem by introducing a deep residual learning framework. Instead of hoping each few stacked layers directly fit a desired underlying mapping, explicitly let these layers fit a residual mapping. Formally, denoting the desired underlying mapping as <span class="math inline">\(H(\mathbf{x})\)</span>, we let the stacked nonlinear layers fit another mapping of <span class="math inline">\(F(\mathbf{x}) := H(\mathbf{x}) âˆ’ \mathbf{x}\)</span>. The original mapping is recast into <span class="math inline">\(F(\mathbf{x})+\mathbf{x}\)</span>. We hypothesize that it is easier to optimize the residual mapping than to optimize the original, unreferenced mapping. To the extreme, if an identity mapping were optimal, it would be easier to push the residual to zero than to fit an identity mapping by a stack of nonlinear layers.</p>
<p>Compared to Highway Network, Residual Network is just a special case when <span class="math inline">\(T (\mathbf{x}, \mathbf{W_T}) = \mathbf{0.5}\)</span>.</p>
<h1 id="training-rnns-as-fast-as-cnns">Training RNNs as Fast as CNNs</h1>
<p>Recurrent neural networks scale poorly due to the intrinsic difficulty in parallelizing their state computations. For instance, the forward pass computation of <span class="math inline">\(h_t\)</span> is blocked until the entire computation of <span class="math inline">\(h_{tâˆ’1}\)</span> finishes, which is a major bottleneck for parallel computing.</p>
<p>This paper introduces a Simple Recurrent Unit (SRU) which operates significantly faster than traditional recurrent implementations. The recurrent unit simplifies state computation and hence exposes the same parallelism as CNNs, attention and feed-forward nets. Specifically, while the update of internal state <span class="math inline">\(c_t\)</span> still makes use of the previous state <span class="math inline">\(c_{tâˆ’1}\)</span>, the dependence on <span class="math inline">\(h_{tâˆ’1}\)</span> in a recurrence step has been dropped. As a result, all matrix multiplications and element-wise operations in the recurrent unit can be easily parallelized across different dimensions and steps.</p>
<p>Most top-performing recurrent neural networks such as LSTMs and GRUs make use of neural gates to control the information flow and alleviate the gradient vanishing (or explosion) problem. Consider a typical implementation,</p>
<span class="math display">\[\begin{equation}\begin{split}
\mathbf{c}_t &amp;= \mathbf{f_t} \odot \mathbf{c}_{t-1} + \mathbf{i}_t \odot \widetilde{\mathbf{x}}_t\\\\
&amp;= \mathbf{f_t} \odot \mathbf{c}_{t-1} + (1 - \mathbf{f}_t) \odot \widetilde{\mathbf{x}}_t
\end{split}\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{f}_t\)</span> and <span class="math inline">\(\mathbf{i}_t\)</span> are sigmoid gates referred as the <em><strong>forget gate</strong></em> and <em><strong>input gate</strong></em>. <span class="math inline">\(\widetilde{\mathbf{x}}_t\)</span> is the transformed input at step <span class="math inline">\(t\)</span>. <span class="math inline">\(\mathbf{i}_t = 1 âˆ’ \mathbf{f}_t\)</span> here for simplicity. The computation of <span class="math inline">\(\widetilde{\mathbf{x}}_t\)</span> also varies in different RNN instances. The paper uses the simplest version that performs a linear transformation over the input vector <span class="math inline">\(\widetilde{\mathbf{x}}_t = \mathbf{Wx}_t\)</span>. Finally, the internal state <span class="math inline">\(\mathbf{c}_t\)</span> is passed to an activation function <span class="math inline">\(g(Â·)\)</span> to produce the output state <span class="math inline">\(\mathbf{h}_t = g(\mathbf{c}_t)\)</span>.</p>
<p>The paper includes two additional features in implementation. First, it adds skip connections between recurrent layers since they are shown quite effective for training deep networks. Specifically, we use highway connections and the output state <span class="math inline">\(\mathbf{h}&#39;_t\)</span> is computed as,</p>
<span class="math display">\[\begin{equation}\begin{split}
\mathbf{h}&#39;_t &amp;= \mathbf{r}_t \odot \mathbf{h}_t + (1 - \mathbf{r}_t) \odot \mathbf{x}_t\\\\
&amp;= \mathbf{r}_t \odot g(\mathbf{c}_t) + (1 - \mathbf{r}_t) \odot \mathbf{x}_t
\end{split}\end{equation}\]</span>
<p>where <span class="math inline">\(\mathbf{r}_t\)</span> is the output of a reset gate.</p>
<p>The associated equations of SRU are given below:</p>
<span class="math display">\[\begin{equation}\begin{split}
\widetilde{\mathbf{x}}_t &amp;= \mathbf{Wx}_t\\\\
\mathbf{f}_t &amp;= \sigma(\mathbf{W}_f\mathbf{x}_t + \mathbf{b}_f)\\\\
\mathbf{r}_t &amp;= \sigma(\mathbf{W}_r\mathbf{x}_t + \mathbf{b}_r)\\\\
\mathbf{c}_t &amp;= \mathbf{f}_t \odot \mathbf{c}_{t-1} + (1 - \mathbf{f}_t) \odot \widetilde{\mathbf{x}_t}\\\\
\mathbf{h}_t &amp;= \mathbf{r}_t \odot g(\mathbf{c}_t) + (1 - \mathbf{r}_t) \odot \mathbf{x}_t
\end{split}\end{equation}\]</span>
<p>We can see that the first three equations can be computed in parallel. And last two equations can be computed quite easily and fast since all operations are element-wise.</p>
<h1 id="reference">Reference</h1>
<ol style="list-style-type: decimal">
<li><a href="https://arxiv.org/pdf/1505.00387.pdf" target="_blank" rel="external">Highway Network</a></li>
<li><a href="https://arxiv.org/pdf/1512.03385.pdf" target="_blank" rel="external">Deep Residual Learning for Image Recognition</a></li>
<li><a href="https://arxiv.org/pdf/1709.02755.pdf" target="_blank" rel="external">Training RNNs as Fast as CNNs</a></li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/RNN/" rel="tag"># RNN</a>
          
            <a href="/tags/DL/" rel="tag"># DL</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/09/15/2017-09-15Seq2seq/" rel="next" title="Sequence To Sequence Models">
                <i class="fa fa-chevron-left"></i> Sequence To Sequence Models
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/09/15/2017-09-15Attention Is All You Need/" rel="prev" title="Attention Is All You Need">
                Attention Is All You Need <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Ember" />
          <p class="site-author-name" itemprop="name">Ember</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">19</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#highway-network"><span class="nav-number">1.</span> <span class="nav-text">Highway Network</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#residual-network"><span class="nav-number">2.</span> <span class="nav-text">Residual Network</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#training-rnns-as-fast-as-cnns"><span class="nav-number">3.</span> <span class="nav-text">Training RNNs as Fast as CNNs</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#reference"><span class="nav-number">4.</span> <span class="nav-text">Reference</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ember</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">Theme &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  








  








  





  

  

  

  
  


  

  

</body>
</html>
