<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="RNN,DL,RL," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.2" />






<meta name="description" content="Contents  Review RL for Sentence Generation GAN for Sentence Generation  Review The details of traditional sequence to sequence models can be found in my previous blog. A little new things here. If we">
<meta name="keywords" content="RNN,DL,RL">
<meta property="og:type" content="article">
<meta property="og:title" content="RL and GAN for Sentence Generation">
<meta property="og:url" content="http://yoursite.com/2017/09/27/2017-09-27RL and GAN for Sentence Generation/index.html">
<meta property="og:site_name" content="EmberNLP">
<meta property="og:description" content="Contents  Review RL for Sentence Generation GAN for Sentence Generation  Review The details of traditional sequence to sequence models can be found in my previous blog. A little new things here. If we">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://yoursite.com/images/2017-09-27RL%20and%20GAN%20for%20Sentence%20Generation/HierarchicalEncoder.png">
<meta property="og:image" content="http://yoursite.com/images/2017-09-27RL%20and%20GAN%20for%20Sentence%20Generation/Seq2seqRL.png">
<meta property="og:image" content="http://yoursite.com/images/2017-09-27RL%20and%20GAN%20for%20Sentence%20Generation/SeqGANRandomness.png">
<meta property="og:updated_time" content="2017-09-27T11:06:17.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="RL and GAN for Sentence Generation">
<meta name="twitter:description" content="Contents  Review RL for Sentence Generation GAN for Sentence Generation  Review The details of traditional sequence to sequence models can be found in my previous blog. A little new things here. If we">
<meta name="twitter:image" content="http://yoursite.com/images/2017-09-27RL%20and%20GAN%20for%20Sentence%20Generation/HierarchicalEncoder.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.2',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/09/27/2017-09-27RL and GAN for Sentence Generation/"/>





  <title>RL and GAN for Sentence Generation | EmberNLP</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">EmberNLP</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/27/2017-09-27RL and GAN for Sentence Generation/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ember">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="EmberNLP">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">RL and GAN for Sentence Generation</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-09-27T11:01:30+10:00">
                2017-09-27
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Paper-Notes/" itemprop="url" rel="index">
                    <span itemprop="name">Paper Notes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="contents">Contents</h1>
<ul>
<li>Review</li>
<li>RL for Sentence Generation</li>
<li>GAN for Sentence Generation</li>
</ul>
<h3 id="review">Review</h3>
<p>The details of traditional sequence to sequence models can be found in my previous <a href="https://embernlp.github.io/2017/09/15/2017-09-15Seq2seq/" target="_blank" rel="external">blog</a>.</p>
<p>A little new things here. If we use sequecen to sequence model to train a cwidehatbot, we need to take prvious dialogue into consideration when we generate next dialogue utterance. Here introduce the hierarchical encoder structure, it is shown below:</p>
<center>
<img src="/images/2017-09-27RL%20and%20GAN%20for%20Sentence%20Generation/HierarchicalEncoder.png">
</center>
<p>Let’s define</p>
<ul>
<li><span class="math inline">\(h\)</span>: input sentence and history/context</li>
<li><span class="math inline">\(\widehat{x}\)</span>: correct reponse (word sequence)</li>
<li><span class="math inline">\((h,\widehat{x})\)</span>: training data</li>
<li><span class="math inline">\(\widehat{x}_t\)</span>: t-th word</li>
<li><span class="math inline">\(\widehat{x}_{1:t}\)</span>: first t words of <span class="math inline">\(\widehat{x}\)</span></li>
</ul>
<p>We have our cost function as:</p>
<span class="math display">\[\begin{equation}\begin{split}
C_t &amp;= -logP_{\theta}(\widehat{x}_t | \widehat{x}_{1:t-1}, h)\\\\
C &amp;= -\Sigma_t log P(\widehat{x}_t | \widehat{x}_{1:t-1}, h)\\\\
&amp;= -log P(\widehat{x}_1 | h) P(\widehat{x}_2 | \widehat{x}_1, h) \cdots P(\widehat{x}_t | \widehat{x}_{1:t-1}, h) \cdots P(\widehat{x}_T | \widehat{x}_{1:T-1}, h)\\\\
&amp;= -logP(\widehat{x} | h)
\end{split}\end{equation}\]</span>
<p>Then maximize the likelihood of generating <span class="math inline">\(\widehat{x}\)</span> given <span class="math inline">\(h\)</span>.</p>
<h3 id="rl-for-sentence-generation">RL for Sentence Generation</h3>
<p>Different from seq2seq structure above, RL is introduced and the model learns to maximize the <em>expected reward</em> instead MLE. Rewards are designed by model developer.</p>
<p>The structure is shown below.</p>
<center>
<img src="/images/2017-09-27RL%20and%20GAN%20for%20Sentence%20Generation/Seq2seqRL.png">
</center>
<p>Our goal is: <span class="math inline">\(\theta^{\ast} = argmax_{\theta} \bar{R}_{\theta}\)</span></p>
<p>The expected reward is:</p>
<span class="math display">\[\begin{equation}\begin{split}
\bar{R}_{\theta} &amp;= \Sigma_h P(h) \Sigma_x R(h,x) P_{\theta} (x|h)\\\\
&amp;= E_{h \sim P(h)} [E_{x \sim P_{\theta} (x|h)} [R(h,x)]]\\\\
&amp;= E_{h \sim P(h), x \sim P_{\theta} (x|h)} [R(h,x)]\\\\
&amp;\approx \frac{1}{N} \Sigma^N_{i=1} R(h^i,x^i) \qquad (sample: \{h^1,x^1\},\{h^2,x^2\},...,\{h^N,x^N\})
\end{split}\end{equation}\]</span>
<p>To update parameters <span class="math inline">\(\theta\)</span>:</p>
<span class="math display">\[\begin{equation}\begin{split}
\nabla \bar{R}_{\theta} &amp;= \Sigma_h P(h) \Sigma_x R(h,x) \nabla P_{\theta} (x|h)\\\\
&amp;= \Sigma_h P(h) \Sigma_x R(h,x) P_{\theta} (x|h) \frac{\nabla P_{\theta} (x|h)}{P_{\theta} (x|h)}\\\\
&amp;= \Sigma_h P(h) \Sigma_x R(h,x) P_{\theta} (x|h) \nabla log P_{\theta} (x|h)\\\\
&amp;= E_{h \sim P(h), x \sim P_{\theta} (x|h)} [R(h,x)\nabla log P_{\theta} (x|h)]\\\\
&amp;\approx \frac{1}{N} \Sigma^N_{i=1} R(h^i,x^i)\nabla log P_{\theta} (x^i|h^i)\\\\
\qquad\\\\
\theta^{new} &amp;\leftarrow \theta_{old} + \eta \nabla \bar{R}_{\theta^{old}}
\end{split}\end{equation}\]</span>
<ul>
<li>If <span class="math inline">\(R(h^i,x^i)\)</span> is positive
<ul>
<li>After updating <span class="math inline">\(\theta\)</span>, <span class="math inline">\(P_{\theta} (x^i|h^i)\)</span> will increase</li>
</ul></li>
<li>If <span class="math inline">\(R(h^i,x^i)\)</span> is negative
<ul>
<li>After updating <span class="math inline">\(\theta\)</span>, <span class="math inline">\(P_{\theta} (x^i|h^i)\)</span> will decrease</li>
</ul></li>
</ul>
<p>We have a summary here, to compare traditional seq2seq model and RL seq2seq model:</p>
<table style="width:72%;">
<colgroup>
<col width="15%">
<col width="27%">
<col width="29%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th>MLE</th>
<th>RL</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Objective Function</td>
<td><span class="math inline">\(\frac{1}{N} \Sigma^N_{i=1} log P_{\theta} (\widehat{x}^i \mid h^i)\)</span></td>
<td><span class="math inline">\(\frac{1}{N} \Sigma^N_{i=1} R(h^i,x^i)logP_{\theta}(x^i,h^i)\)</span></td>
</tr>
<tr class="even">
<td>Gradient</td>
<td><span class="math inline">\(\frac{1}{N} \Sigma^N_{i=1} \nabla log P_{\theta} (\widehat{x}^i \mid h^i)\)</span></td>
<td><span class="math inline">\(\frac{1}{N} \Sigma^N_{i=1} R(h^i,x^i) \nabla logP_{\theta}(x^i,h^i)\)</span></td>
</tr>
<tr class="odd">
<td>Training Data</td>
<td>{<span class="math inline">\((h^1,\widehat{x}^1),...,(h^N,\widehat{x}^N)\)</span>} <span class="math inline">\(R(h^i, \widehat{x}^i)=1\)</span></td>
<td>{<span class="math inline">\((h^1,x^1),...,(h^N,x^N)\)</span>} Sampling as training data weighted by <span class="math inline">\(R(h^i, x^i)\)</span></td>
</tr>
</tbody>
</table>
<p>Two things to notice here:</p>
<ol style="list-style-type: decimal">
<li>Model is trained using supervised seq2seq structure first , results will be later used for initialization.</li>
<li>Add a baseline <span class="math inline">\(\frac{1}{N} \Sigma^N_{i=1} (R(h^i,x^i)-b) \nabla logP_{\theta}(x^i,h^i)\)</span></li>
</ol>
<h3 id="gan-for-sentence-generation">GAN for Sentence Generation</h3>
<p>Using GAN to generate sentence is quite straightforward.</p>
<p>First, we initialize generator G and discriminator D Then, in each iteration:</p>
<ul>
<li>Sample real sentences <span class="math inline">\(x\)</span> from database</li>
<li>Generate sentences <span class="math inline">\(\widetilde{x}\)</span> by G</li>
<li><p>Update D to increase <span class="math inline">\(D(x)\)</span> and decrease <span class="math inline">\(D(\widetilde{x})\)</span></p></li>
<li><p>Update G such that <span class="math inline">\(\widetilde{x}\)</span> will have higher score from D.</p></li>
</ul>
<p>Another application which is much similar to sentence generation is chat-bot, using GAN to train a chat-bot is also quite similar:</p>
<p>First, initilize generator G(Encoder-Decoder structure) and discriminator D (rnn based structure) Then in each iteration:</p>
<ul>
<li>Sample real history <span class="math inline">\(h\)</span> and sentence <span class="math inline">\(x\)</span> from database</li>
<li>Sample real history <span class="math inline">\(h&#39;\)</span> from database, and generate sentences <span class="math inline">\(\widetilde{x}\)</span> by <span class="math inline">\(G(h&#39;)\)</span>.</li>
<li><p>Update <span class="math inline">\(D\)</span> to increase <span class="math inline">\(D(h,x)\)</span> and decrease <span class="math inline">\(D(h&#39;,\widetilde{x})\)</span>.</p></li>
<li><p>update G such that <span class="math inline">\(G(h&#39;)\)</span> will have higher score from D.</p></li>
</ul>
<p>One important thing to notice! When we generate sentences from G, every word is sampled from a predicted distribution. So there exists randomness between G and D, and backpropogation does not work! This is illustrated below:</p>
<center>
<img src="/images/2017-09-27RL%20and%20GAN%20for%20Sentence%20Generation/SeqGANRandomness.png">
</center>
<p>The blue dash line shows the randomness. It implies that a small change of the parameters in the G will not affect its output. So, RL shows up.</p>
<p>Consider the output of D as reward, we update G to increase D so as to get maximum reward.</p>
<span class="math display">\[\begin{equation}\begin{split}
\nabla \bar{R}_{\theta} &amp;\approx \frac{1}{N} \Sigma^N_{i=1} (R(h^i,x^i)-b) \nabla log P_{\theta} (x^i \mid h^i)\\\\
&amp;= \frac{1}{N} \Sigma^N_{i=1} (D(h^i,x^i)-b) \nabla log P_{\theta} (x^i \mid h^i)
\end{split}\end{equation}\]</span>
<p>Different from typical RL, D will update.</p>
<p>Another important issue about the above algorithm is that we use the same reward for the entire output sentence, which means the probability of every word will increase or decrease simultaneously. This is not we want it to do and we can improve it! Let’s change the gradient a little bit.</p>
<span class="math display">\[\begin{equation}\begin{split}
\nabla \bar{R}_{\theta} &amp;= \frac{1}{N} \Sigma^N_{i=1} (D(h^i,x^i)-b) \nabla log P_{\theta} (x^i \mid h^i)\\\\
&amp;\approx \frac{1}{N} \Sigma^N_{i=1} \Sigma^T_{t=1} (Q(h^i,x^i_{1:t})-b) \nabla log P_{\theta} (x^i_t \mid h^i, x^i_{1:t-1})
\end{split}\end{equation}\]</span>
<p>It raises another question, how to get the value of <span class="math inline">\(Q(h^i,x^i_{1:t})\)</span>?</p>
<p><strong>MC Search</strong></p>
<p>Here is an example. Out target is Q(“What is your name?”, “I”)</p>
<p>We put “What is your name?” into generator G, and force it to generate “I” as the first word and then let it continue generating other words. Due to the randomness we mentioned abvoe, then we can get many different sentences. Finally, we put all the generated sentences into the discriminator D to obtain the scores, and average them to get the reward for a specific word.</p>
<span class="math display">\[\begin{equation}\begin{split}
x^A &amp;= &quot;I \space am \space John&quot; &amp;D(h^i,x^A) = 1.0\\\\
x^B &amp;= &quot;I \space am \space happy&quot; &amp;D(h^i,x^B) = 0.1\\\\
x^C &amp;= &quot;I \space don&#39;t \space know&quot; &amp;D(h^i,x^C) = 0.1\\\\
x^D &amp;= &quot;I \space am \space superman&quot; &amp;D(h^i,x^D) = 0.8\\\\
\end{split}\end{equation}\]</span>
<p><span class="math display">\[Q(h^i, &quot;I&quot;) = \frac{1.0+0.1+0.1+0.8}{4} = 0.5\]</span></p>
<p><strong>Rewarding Partially Decoded Sequences</strong></p>
<p>Training a discriminator D that is able to assign rewards to both fully and partially decoded sequences. We can simply break generated sequences into partial sequences.</p>
<p>A little trick here. When we train G at the begining, it’s hard for G to learn. So we sample some real data to teach G what is the good answer.</p>
<h3 id="reference">Reference</h3>
<ol style="list-style-type: decimal">
<li>Deep Reinforcement Learning for Dialogue Generation</li>
<li>SeqGAN: Sequence Generative Adversarial Nets wirh Policy Gradient</li>
<li>Adversarial Learning for Neural Dialogue Generation</li>
</ol>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/RNN/" rel="tag"># RNN</a>
          
            <a href="/tags/DL/" rel="tag"># DL</a>
          
            <a href="/tags/RL/" rel="tag"># RL</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/09/25/2017-09-25GAN/" rel="next" title="Generative Adversarial Network">
                <i class="fa fa-chevron-left"></i> Generative Adversarial Network
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="Ember" />
          <p class="site-author-name" itemprop="name">Ember</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
            
              <a href="/archives/">
            
                <span class="site-state-item-count">22</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">9</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#contents"><span class="nav-number">1.</span> <span class="nav-text">Contents</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#review"><span class="nav-number">1.0.1.</span> <span class="nav-text">Review</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#rl-for-sentence-generation"><span class="nav-number">1.0.2.</span> <span class="nav-text">RL for Sentence Generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#gan-for-sentence-generation"><span class="nav-number">1.0.3.</span> <span class="nav-text">GAN for Sentence Generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#reference"><span class="nav-number">1.0.4.</span> <span class="nav-text">Reference</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ember</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" href="https://hexo.io">Hexo</a></div>

  <span class="post-meta-divider">|</span>

  <div class="theme-info">Theme &mdash; <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.2</div>


        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.2"></script>



  
  

  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>


  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.2"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  








  








  





  

  

  

  
  


  

  

</body>
</html>
